Araştırma Makalesi Gönderim / Received: 08/08/2023 Research Article Kabul / Accepted: 18/09/2023 Hukuk Fakültesi Dergisi Ankara Hacı Bayram Veli University Faculty of Law Review ISSN: 2651-4141 e-ISSN: 2667-4068 Cilt / Volume XXVII Ekim / October 2023 Sayı / No. 4 YAPAY ZEKAVE CEZA HUKUKU SORUMLULUĞU ARTIFICIAL INTELLIGENCE AND CRIMINAL LAW RESPONSIBILITY Berrin AKBULUT* ÖZET 10.34246/ahbvuhfd.1339596 <BR> Yapay zekanın üzerinde uzlaşılmış bir tanımı bulunmamaktadır. Sürekli gelişmekte ve yeni özelliklere sahip olmaktadır. Bilim insanları yapay zekanın insan gibi düşünmesi, karar vermesi ve hareket etmesi üzerine çalışmaktadır. Hatta öğrenebilen ve gelecekte insan zekasından <BR>bağımsız gelişebilecek bir yapay zekâ kavramına doğru bir gidiş söz konusudur. Yapay zekada yaşanan bu gelişmeler, yapay zekanın ceza hukuku bakımından sorumlu tutulup tutulamayacağı tartışmasının yaşanması sonucunu doğurmuştur. Yapılan tartışmalar aynı zamanda mevcut ceza hukuku kavramlarının yeniden yorumlanması, genişletilmesi ve yeni belirlemelerin yapılması neticesini de ortaya çıkarmıştır. Bu çalışmada ceza hukuku sorumluluğu için aranan suçun unsurları, kusurluluk kavramları yapay zeka açısından değerlendirilecektir. Ayrıca yapay zeka kavramı, gelecekteki etkileri, suç işlemedeki rolü ve yapay zekanın cezalandırılıp cezalandırılmayacağı üzerinde durulacaktır. Anahtar Kelimeler: Yapay zeka, Makine öğrenme, Hareket, İrade özgürlüğü, Kusur. ABSTRACT There is no agreed definition of artificial intelligence. It is constantly developing and gaining new features. Scientists are working on artificial intelligence to think, decide and act like humans. There is even a move towards the concept of artificial * Prof. Dr., Selçuk Üniversitesi Hukuk Fakültesi, Ceza ve Ceza Muhakemesi Hukuku Anabilim Dalı/KONYA, e-posta: bakbulut@selcuk.edu.tr, ORCID: 0000-0001-8045-2784, DOI: 10.34246/ahbvuhfd.1339596. * İntihal / Plagiarism: Bu makale intihal programında taranmış ve en az iki hakem incelemesinden geçmiştir. / This article has been scanned via a plagiarism software and reviewed by at least two referees. Bu eser Creative Commons Atıf-GayriTicari 4.0 Uluslararası Lisansı ile lisanslanmıştır This work is licensed under Creative Commons Attribution-NonCommercial 4.0 International License. 267 intelligence that can learn and develop independently of human intelligence in the future. These developments in artificial intelligence have led to a debate on whether artificial intelligence can be held responsible in terms of criminal law. The debates also result in the reinterpretation and expansion of existing criminal law concepts and the making of new determinations. In this study, the elements of the crime sought for criminal law responsibility and the concept of culpability will be evaluated in terms of artificial intelligence. In addition, the concept of artificial intelligence, its future effects, its role in committing crimes and whether it can be punished or not will be emphasized. Keywords: Artificial intelligence, Machine learning, Act, Freedom of will, Culpability. EXTENDED ABSTRACT There is no agreed definition of artificial intelligence. It is constantly developing and gaining new features. Scientists are working on artificial intelligence to think, decide and act like humans. There is even a move towards the concept of artificial intelligence that can learn and develop independently of human intelligence in the future. These developments in artificial intelligence have led to a debate on whether artificial intelligence can be held responsible in terms of criminal law. The debates also result in the reinterpretation and expansion of existing criminal code concepts and the making of new determinations. Artificial intelligence and artificially intelligent beings can cause the violation of personal values such as life, bodily inviolability, privacy, personal data, honor, property, and the commission of cybercrimes. In fact, productive artificial intelligence systems can be used to produce content such as images, videos and music without the need for human intervention, and criminal acts can be committed. While trying to determine the responsibility of the people who produce and use artificial intelligence in these crimes, there has also been a debate on whether an artificial intelligence that learns from the information it collects on the basis of an algorithm, calculates possibilities, experiences, makes decisions, draws conclusions, chooses and implements the appropriate behavior can also be responsible in terms of criminal law. The fact that the determinations made in criminal law are based on the real person, the human being, has led to the conclusion that the discussions on artificial intelligence are also made in the context of human characteristics. The discussions focus on whether artificial intelligence can be accepted as a person, whether it has will and freedom of will. Positive answers to these questions will lead to the conclusion that artificial intelligence has the ability to act and the ability of fault and therefore will be responsible in terms of criminal law. Since the discussions are based on human beings, it is accepted by the majority of the authors in the doctrine that it is not possible to talk about a real decision of the artificial intelligence based on its own evaluation, that it sets goals for itself within this framework and that it determines its actions according to these goals, and that it cannot form its own will. Likewise, when it is a system that is independent of human control and not limited to its software, when it has the ability to understand the legal meaning and content of its actions, when it does not choose the right and fulfill the wrong with its free will, it will be at fault, but it is accepted that it is not at fault today. It should be noted that in the doctrine, it is not generally rejected that artificial intelligence will have the ability to act and the ability to fault at a later stage. In the future, when the criminal law responsibility of artificial intelligence is accepted, it is seen as an important problem in the doctrine to ensure the expected purpose of the punishment and what kind of punishments will be applied, and determinations are made. The developments in the field of artificial intelligence, which will lead to the acceptance of criminal law responsibility, will not only result in considering will not only result in taking into account the unjust content of the act in terms of determining the punishment (Art. 61 of the TPC), but will also lead to the consideration of artificial intelligence itself. The discussions on the criminal law responsibility of artificial intelligence have led to the return to non-human-centered criminal law concepts, as well as the reinterpretation, expansion and redefinition of existing criminal Law concepts. In fact, the theoretical and conceptual determinations expressed in the doctrine of criminal law have led to the idea of creating criminal law for machines. In this study, the elements of the crime sought for criminal law responsibility and the concept of culpability will be evaluated in terms of artificial intelligence. In addition, the concept of artificial intelligence, its future effects, its role in committing crimes and whether it can be punished or not will be emphasized. GİRİŞ Bilişim alanında, bu anlamdaprogramlama alanında yaşanan gelişmeler hayatımızda yapay zeka kavramının ve yapay zekaya sahip varlıkların yer almasını sağlamıştır. Yapay zeka alanında yaşanan gelişmeler çok hızlı bir şekilde artmakta ve hayatımızın her alanında yer almaktadır. Getirdiği kolaylık, hızlılık, verimlilik gibi nedenler yapay zekanın ve yapay zekaya sahip varlıkların üretilmesini ve kullanımını artırmaktadır. Teknolojik gelişmelerin, programın yalnızca araç olarak kullanıldığı dönemlerde ceza hukuku açısından yalnızca bu programları kullanarak suç işleyen kişilerin sorumluluğu üzerinde durulmakta, bilişim alanında yaşanan gelişmelerin ortaya çıkardığı yeni suç şekilleriyle uğraşılmaktaydı. Ancak yapay zekada yaşanan gelişmeler ve yapay zekanın öğrenme, deneyimleme, seçme ve karar verme kapasitesine sahip olması, ileride sahip olacağı gücün sorgulanması, insanlığın geleceğinden endişe duyulması ve ceza hukuku açısından da yeni tartışmaların yaşanması sonucunu doğurmuştur. Yapay zekâ ve yapay zekalı varlıklar, kişilerin hayat, vücut dokunulmazlığı, özel yaşamın gizliliği, kişisel veriler, şeref, malvarlığı gibi kişisel değerlerin ihlâl edilmesini, bilişim suçlarının işlenmesini sağlayabilmektedir. Dolayısıyla da ceza hukukunda hem yapay zekanın ceza sorumluluğunun bulunup bulunmadığı tartışılmakta hem de yapay zekanın fiillerinden, üreticisinin, programcısının, kullanıcısınınsorumlu olup olmadığı üzerinde durulmaktadır. Ceza hukukunda insandan kaynaklanan davranışın ceza hukuku sorumluluğu doğurduğunun kabul edilmesi, kabul edilen müesseselerin insana özgü değerlendirilmesi, yapay zekanın bugün ve gelecekte cezai sorumluluğunun kabul edilip edilemeyeceği noktasında tartışmalar yaşanması sonucunu doğurmaktadır. I. YAPAY ZEKA A. Genel Olarak Yapay zeka (Artificial Intelligence-AI) kavramı, ilk defa 1955 yılında, 1956 yazında Amerika Birleşik Devletlerinin New Hampshire eyaletinde gerçekleştirilecek Dartmouth Konferansı için John McCarthy ve ekibi tarafından hazırlanan araştırma proje önerisinde yer almıştır1. Bu çalışmada yapay zeka, yapay zekâyı “akıllı makineler yapma mühendisliği ve bilimi” olarak tanımlanmıştır. Yapay zeka alanında 1997 yılına kadar çok önemli mesafe alınamamış, 1997 yılında ise saniyede milyonlarca hamle hesaplayabilen IBM şirketinin ürettiği DeepBlue isimli bilgisayarın, satranç oyununda dünya şampiyonu Gary Kasparov’u yenmesiyle yapay zekâ yeniden gündeme gelmiştir2. 1990’larda yapay zeka kendi başına karar verememekteydi. Sadece yüklenen programlar sayesinde çıkarımlar yapmakta ve buna göre hareket etmektedir. Ancak günümüzde makine öğrenmesi, hatta derin öğrenme yapabilmektedir3. 1 Özgür Taşdemir/Ümit Vefa Özbay/Burhanettin Onur Kireçtepe, “Robotların Hukuki ve Cezai Sorumluluğu Üzerine Bir Deneme”, AÜHFD, 69(2) 2020, s. 797; Osman Gazi Güçlütürk, Türk Hukukunda Makine Öğrenmesine Dayalı Yapay Zekada Verinin Hukuka Uygun Şekilde Kullanılması, Galatasaray Üniversitesi Sosyal Bilimler Enstitüsü, Doktora Tezi, İstanbul 2021, s. 25; <https://cbddo.gov.tr/sss/yapay-zeka/>, Erişim Tarihi 8 Ağustos2023. Yapay Zekanın tarihçesi için bkz.: Güneş Okuyucu Ergün, “Machina Sapiens”, AÜHFD, 72(2), 2023, 717-758, s. 721 vd. 2 Hakan Aksoy, “Yapay Zekalı Varlıklar ve Ceza Hukuku”, International Journal of Economics, Politics, Humanities & Social Sciences, 4(1), 2021, s. 12, 13. 3 Ayşe Nur Merve Yazıcı, Otonom Aracın Sebep Olduğu Zararlardan Üreticinin Kusursuz Yapay zekanın herkes tarafından ittifakla kabul edilen bir tanımı bulunmamaktadır4. Ancak tanımlamalara bakıldığında özelliklerin kullanılarak benzer tanımlar yapıldığı görülmektedir. Cumhurbaşkanlığı Dijital Dönüşüm Ofisine göre “Yapay zekâ, bir bilgisayarın veya bilgisayar kontrollü robotun, genellikle akıllı varlıklarla ilişkili görevleri yerine getirme yeteneğidir. Terim sıklıkla akıl yürütme, anlam keşfetme, genelleme veya geçmiş deneyimlerden öğrenme gibi insanlara özgü entelektüel süreçlerle donatılmış sistemler geliştirmek amacıyla kullanılmaktadır”5. Bir tanıma göre, yapay zeka “karmaşık bir şeyi algılama ve uygun kararlar verme” olarak tanımlanmaktadır6. Başka bir tanıma göre, “yapay zekâ, otonom (özerk) bir sistemin dış verileri doğru şekilde yorumlayabilme, bu tür verilerden çıkarımlar yaparak öğrenebilme ve öğrendiklerini esnek bir uyarlama yoluyla belirli hedeflere ve görevlere ulaşmak için kullanabilme becerisi olarak”7 tanımlanmaktadır. Bir diğer tanım olarak, insanların doğal olarak sahip oldukları zeka ile çözdükleri problemleri çözme becerisine sahip makineler belirlemesi yapılmaktadır8.Bir başka tanım yapay zekayı, “tecrübelerden öğrenebilen, öğrendiklerini muhakeme edebilen; şekilleri, gürüntü ve örüntüleri tanıyabilen, karmaşık problemlere çözümler üretebilen, lisanı anlayarak kelimeler ile işlem yapabilen ve bilişim dünyasına farklı bir bakış açısı kazandıran bir bilim dalı” olarak tanımlamaktadır9. Avrupa Birliği Parlamentosu, yapay zekayı, “makinelerin akıl yürütme, öğrenme, planlama ve yaratıcılık gibi insanlara benzer davranışlar sergileme kabiliyeti” olarak tanımlamıştır. Avrupa Komisyonun Yapay Zekâ Tüzük Teklifi’nin 3(1) maddesinde, yapay zeka kavramı kullanılmamış, yapay zeka sistemi kavramı kullanılmış ve bu ifadenin tanımı yapılmıştır. Bu tanıma göre, “yapay zekâ sistemi Ek I’de listelenen teknik ve yaklaşımlardan bir veya daha fazlası ile geliştirilen ve insan tarafından oluşturulmuş amaçlar kapsamında, etkileşimde bulundukları ortamları etkileyen içerik, tahmin, öneri veya karar Sorumluluğu, Adalet Yayınevi, 2023, s. 41. 4 Farklı tanımlamalar için bkz.: Cannur Ercan, “Robotların Fiillerinden Doğan Hukuki Sorumluluk Sözleşme Dışı Sorumluluk Hallerinde Çözüm Önerileri”, TAAD, (40), 2019, s. 20. 5 <https://cbddo.gov.tr/sss/yapay-zeka/.>, Erişim Tarihi 25 Ağustos 2023. <BR> 6 Aksoy, s. 12. 7 Tanım için bkz.: Sinan Sami Akkurt, “Yapay Zekânın Otonom Davranışlarından Kaynaklanan Hukukî Sorumluluk”, Uyuşmazlık Mahkemesi Dergisi, 7(13), 2019, s. 41. 8 Asena Damla Şahin, “Otonom Araçların Hukuki. Sorumluluğunun Türk ve Alman Hukuku Kapsamında Değerlendirilmesi”, Suç ve Ceza, (4), 2020, s. 980. 9 Ercan Öztemel, “Yapay Zekâ ve İnsanlığın Geleceği”, <https://tuba.gov.tr/files/yayinlar/ <BR>bilim-ve-dusun/TUBA-978-605-2249-48-2_Ch9.pdf>, Erişim Tarihi 5 Ağustos 2023, s. 101. gibi çıktılar üretebilen yazılım anlamına gelmektedir.”EK I’de geçen teknikler ise: “(a) Gözetimli, gözetimsiz ve pekiştirmeli öğrenme de dahil olmak üzere derin öğrenmenin de aralarında bulunduğu çok çeşitli yöntemleri kullanan makine öğrenmesi teknikler, (b) Bilgi temsili, tümevarımsal programlama, bilgi tabanları, çıkarım ve tümdengelim sistemleri, (sembolik) akıl yürütme be uzman sistemler dahil olmak üzere mantık ve bilgiye dayalı teknikler, (c) İstatistiksel yaklaşımlar, Bayes tahmini, araştırma ve optimizasyon metotları” şeklinde belirtilmiştir10. Yapay zeka kanaatimizce; insan zekâsına (doğal zekaya) ait algılama, yorumlama, sonuç çıkarma, öğrenme, uygulama gibi faaliyetlerin yeni ve daha etkili çözümlere ulaşabilmek adına makineler tarafından yapılması olarak tanımlanabilir11. B. Makine Öğrenme Yapay zeka kapsamında geleneksel programlama ve bu programlarla insan davranışlarını belirli bir ölçekte taklit edilmesi söz konusu olsa da bugün yapay zeka denildiğinde “makine öğrenmesi (machine learning)” ve “derin öğrenme (deep learning)” ifade edilmektedir12. Makine öğrenimi, tükettikleri verilere göre öğrenen ya da performansı iyileştiren sistemler oluşturmaya odaklanan bir yapay zeka (AI) alt kümesidir13. Kendi kendine öğrenme olarak da adlandırılan makine öğreniminde sistem davranışlarını/tepkilerini kullanıcılarının müdahalesi olamadan dış dünyadan elde ettikleri izlenimler ile otomatik olarak değiştirebilmektedir. Makine öğreniminde sistem kendi algoritmalarını değiştirebilmekte, bir insan gibi öğrenebilmekte ve kendi deneyimleri ile günden güne gelişebilmektedir14. Geleneksel programlamada girdiler ve bu girdilere uygulanacak işlemler programcılar tarafından komutlar halinde tek tek kodlanırken, makine öğrenmesinde girdiler ve 10 Güçlütürk, s. 31, 32; Armağan Ebru Bozkurt-Yüksel, “Avrupa Komisyonu’nun Yapay Zekâ Tüzük Teklifi’ne Genel Bir Bakış”, TAAD, (51), 2022, s. 21. 11 Bkz.: Aksoy, s. 12; Yazıcı, s. 41; Ercan, s. 20. 12 Güçlütürk, s. 47. 13 <https://www.oracle.com/tr/artificial-intelligence/machine-learning/what-is-machine<BR>learning/>, Erişim Tarihi 3 Ağustos 2023. 14 Şahin, s. 980, 981. çıktılar programcılar tarafından verilmekle birlikte istenen çıktılara ulaşmak için yapılacak işlemler bilgisayar tarafından bulunarak, model adı verilen bir veri yapısının içerisine kaydedilmektedir15.Makine öğrenimi, belirli görevleri yerine getirmeleri için sağlanan verilerden öğrenen sistemlerdir. Gelişmiş görevlerde insan için gerekli algoritmaları elle oluşturmak zor olabildiği için uygulamada, makinenin kendi algoritmasını geliştirmesine yardımcı olmak daha etkili kabul edilmektedir16. Makine öğrenmesi farklı şekillerde gerçekleştirilmektedir. Bunlar denetimli öğrenme (supervised learning-etiketli bir veri kümesi (labeled dataset) kullanılmasıdır. Hangi verinin hangi bilgiye karşılık geldiği bilindiğinden bilinen bir girdi seti ile bunlara denk gelen çıktıları alıp algoritmanın daha önce hiç görmediği yeni verilere en uygun çıktıları üretmek için kullanılan bir makine öğrenmesi modelidir), denetimsiz öğrenme (unsupervised learning-etiketsiz veriler kullanır. Etiketsiz veriler arasındaki gizli kalmış yapıyı/örüntüyü bulmaya çalışarak kendi kendine öğrenme biçimi sergilenir)17, pekiştirmeli öğrenme (reinforcement learning-dünya algısına dayalı bir öğrenme biçimidir. Her eylem ortamda bir etki oluşturmakta ve ortam, öğrenme algoritmasına yol gösteren ödüller biçiminde dönütler vermektedir)18, yarı denetimli öğrenme (semi-supervised learning- uygun 15 Güçlütürk, s. 49. 16 <https://tr.wikipedia.org/wiki/Makine_%C3%B6%C4%9Frenimi#:~:text=Makine%20 <BR>%C3%B6%C4%9Frenimi %20veya%20makine%20%C3%B6%C4%9Frenmesi,konu%20 <BR>edinen%20bir%20bilim%20dal%C4%B1d%C4%B1r>, Erişim Tarihi 1 Ağustos 2023. 17 Hatice Candan, “Adım Adım Makine Öğrenmesi Bölüm 4: Denetimli Öğrenme ve Denetimsiz Öğrenme Arasındaki Fark”, <https://medium.com/machine-learning-t%C3%BCrkiye/ <BR>ad%C4%B1m-ad%C4%B1m-makine-%C3%B6%C4%9Frenmesi-b%C3%B6l%C3%BCm<BR>4-denetimli-%C3%B6%C4%9Frenme-ve-denetimsiz-%C3%B6%C4%9Frenme<BR>aras%C4%B1ndaki-fark-4aa174983380>, Erişim Tarihi 4 Ağustos 2023. 18 AlphaZero, pekiştirmeli öğrenmeyi kullanarak birkaç gün kendi kendine oynadıktan sonra go, satranç ve shogi (Japon satrancı) oynayan en güçlü programları yenmiştir. DeepMind programı iddia edildiğine göre önceden programlanmayıp, tecrübelerinden öğrenmektedir. Programın kodlarında hiçbir değişiklik yapmadan, DeepMind’ın yapay zekası oyunu nasıl oynayacağını anlamakta ve yeterince sayıda oynadıktan sonra birçok insandan daha iyi oynayacak seviyeye gelmektedir: <https://tr.wikipedia.org/wiki/ <BR>DeepMind#:~:text=DeepMind%20Technologies%2C%20Alphabet%20Inc.’,te%20Goog<BR>le%20taraf%C4%B1ndan%20sat%C4%B1n%20al%C4%B1nm%C4%B1%C5%9Ft%C4% <BR>B1r>, Erişim Tarihi 04.08.2023. Deep Mind şirketinin kodlama yapması için geliştirdiği AlphaCode AI, ortalama bir yazılımcı kadar başarılı bir şekilde kod yazabilmektedir: Papuççiyan, Arden, “DeepMind’dan yazılımcılar ile rekabet edebilen yapay zeka: AlphaCode AI”, <https://webrazzi.com/2022/02/03/deepmind-dan-yazilimcilar-ile-rekabet-edebilen-yapay<BR>zeka-alphacode-ai/>, Erişim Tarihi 4 Ağustos 2023. işlev ya da sınıflandırıcılar oluşturmak için etiketli ve etiketsiz örnekleri birlikte ele alır)19 ve kendi kendine denetimli öğrenmedir (self-supervised learning-modelin verilerin bir kısmından yararlanarak diğer kısmı tahmin etmek ve etiketleri doğru bir şekilde oluşturmak için kendini eğittiği bir makine öğrenimi yaklaşımıdır)20. C. Derin Öğrenme Derin öğrenme (Deep Learning), dijital sistemlerin yapılandırılmamış, etiketlenmemiş verilere dayalı olarak öğrenmesini ve kararlar almasını sağlamak üzere yapay sinir ağlarını kullanan makine öğrenmesi için kullanılmaktadır21.Derin öğrenme, nesleri tanıma, dil işleme, konuşma tanıma gibi alanlarda çok katmanlı yapay sinir ağlarını kullanarak verilerle öğrenen bir makine öğrenme biçimidir22. Derin öğrenme, insan beyninin çalışma şekline göre genel hatlarıyla modellenen algoritmalar olan <BR>sinir ağlarının <BR>katmanları tarafından desteklenmektedir23. Sinir ağlarında bulunan nöronlar tek tek farklı katmanlar halinde düzenlenerek giriş katmanına, gizli ara katmanlara ve çıkış katmanına ayrılabilmektedir24. Farklı katmanlardaki nöronlar bilgiyi işlemek için çok karmaşık şekilde birbiriyle bağlantılıdır. Bu ağlar öğrenme yetisine sahiptir. Bir bağlantı tekrar tekrar kullanıldığında bağlantının gücü ve önemi 19 <https://tr.wikipedia.org/wiki/Makine_%C3%B6%C4%9Frenimi#:~:text=Makine%20 <BR>%C3%B6%C4%9Frenimi%20veya%20makine%20%C3%B6%C4%9Frenmesi,konu%20 <BR>edinen%20bir%20bilim%20dal%C4%B1d%C4%B1r>, Erişim Tarihi 4 Ağustos 2023. 20 “Çoğu makine öğrenimi tekniği, tahminlerde bulunmak için eğitim veri kümeleri gerektirir. Veri bilimcilerin, yapay zekanın girdi verilerini anlamasını ve yeni veriler hakkında doğru tahminler yapmasını sağlamak için eğitim veri kümelerindeki gözlemleri manuel olarak veya veri etiketleme araçlarıyla etiketlemesi gerekir. Eğitim veri setinin çok büyük olduğu durumlarda, eğitim verilerini manuel olarak etiketlemek oldukça maliyetli ve zaman alıcı olabilir. Kendi kendini denetleyen öğrenme, veri etiketleme gerekliliğini ortadan kaldırır. Bilgisayarların verileri kendilerinin etiketlemesini, sınıflandırmasını ve analiz etmesini sağlar”, “Self-Supervised Learning Nedir?”, <https://devhunteryz.wordpress.com/2022/03/23/ <BR>self-supervised-learningkendi-kendini-denetleyen-ogrenme/#:~:text=Kendi%20kendi<BR>ne%20denetimli%20%C3%B6%C4%9Frenme%2C%20modelin,denetimli%20bir%20<BR>%C3%B6%C4%9Frenme%20problemine%20d%C3%B6n%C3%BC%C5%9Ft%C3%BCr <BR>%C3%BCr<, Erişim Tarihi 4 Ağustos 2023. 21 <https://azure.microsoft.com/tr-tr/resources/cloud-computing-dictionary/what-is-deep<BR>learning/>, Erişim Tarihi 4 Ağustos 2023. 22 Yazıcı, s. 41. 23 <https://www.oracle.com/tr/artificial-intelligence/machine-learning/what-is-deep<BR>learning/>, Erişim Tarihi 3 Ağustos 2023. 24 Şahin, s. 981. artmaktadır25. Derin öğrenme yapay zeka sistemlerinin altında yer alan bir öğrenme yöntemidir. Derin öğrenme, makine öğrenme şekillerinde (denetimli, denetimsiz öğrenme gibi) kullanılabilecek bir sistemdir. Derin öğrenmenin bulunmadığı yapay zeka yaklaşımlarında, öznitelik denilen verilerin sisteme girilmesi ve girilen bu verilerin kullanılması söz konusudur. Makine verileri işlerken öznitelik çıkarımını kendisi yapmamakta, önceden girilen verileri kullanmaktadır. Derin öğrenmede ise, makinenin bu özniteliği kendisinin çıkarması hedeflenmektedir. Katmanlı bir öğrenme metodu olan bu yaklaşımda ilk önce en önemsiz nitelikteki özelliklerden başlanır ve en önemli özelliğe doğru çıkılır. Her bir katmanda çok geniş bir yapay sinir ağı bulunmaktadır. Bu nedenle de öğrenme ve karmaşık problemleri çözme yetenekleri son derece güçlüdür26.Büyük ve karmaşık veri kümelerini analiz etmek, karmaşık ve doğrusal olmayan görevleri gerçekleştirmek, metin, ses veya resimlere genellikle insanlardan daha hızlı ve daha doğru yanıt vermek için derin öğrenme teknolojisi kullanılmaktadır. Örneğin, otonom araçların görüntüleri işleyip yayaları diğer nesnelerden ayırt etmesini ya da akıllı ev cihazlarınızın sesli komutlarınızı anlamasını sağlayan şey derin öğrenmedir27. Derin öğrenmede yazılımcı da dahil olmak üzere sürece katılanlar sistem üzerindeki kontrolünü kaybetmektedir. Bununla beraber, yapay zeka yaptığı şeyin insan bakımından önemine veya değerine ilişkin bir fikre sahip değildir28. D.Yapay Zekanın Gelecekteki Etkisi Teknoloji gelişirken aynı zamanda suç işlemede kullanılması da artmaktadır. Algılanması zor ve savunması daha da zor olan otomatik, karmaşık saldırılar başlatmak için yapay zekadan (AI) yararlanılmaktadır. Yapay zeka destekli saldırılar, geleneksel siber saldırılardan önemli ölçüde daha fazla zarar verme potansiyeline sahip olup, AI, güvenlik açıklarını taramak, bilgileri araştırmak ve hedefli saldırılar başlatmak gibi görevleri otomatikleştirmek için kullanılabilmektedir. Yapay zeka destekli siber saldırıların kullanımı giderek yaygınlaşmakta ve gelecekte de daha fazla suç işlemede kullanılacaktır29. 25 Zeynel T. Kangal, Yapay Zeka ve Ceza Hukuku, Onikilevha Yayınları, 2021, s. 26. 26 Serhat Can Alkan, “Yapay Zeka ve Doğal Dil İşleme (NLP)”, <https://www. <BR> hukukvebilisimdergisi.com/yapay-zeka-ve-dogal-dil-isleme-nlp/>, Erişim Tarihi 29 Temmuz 2023. 27 <https://azure.microsoft.com/tr-tr/resources/cloud-computing-dictionary/what-is-deep<BR>learning/>, Erişim Tarihi 4 Ağustos 2023. 28 Kangal, s. 26. 29 Marcin Frąckiewicz, “Yapay Zeka ve Siber Suçları Önleme: Akıllı Sistemler Siber Tehdit Yapay zekada, öğrenebilen ve gelecekte insan zekasından <BR>bağımsız gelişebilecek bir yapay zekâ kavramına doğru yönelim söz konusudur. Bu yönelimin, insanın kendisine yardımcı olabilecek belki de kendisinden daha zeki, insan ötesi varlıklar meydana getirme düşünün bir ürünü olduğu ifade edilmektedir30.Ancak bu düşün gerçekleşmesi insanlığın yok olması tehlikesini ortaya çıkaracaktır. Nitekim OpenAI ve Google DeepMind programlarının yöneticileri de dahil olmak üzere bilim insanları, yapay zekanın insanlığın yok oluşuna neden olabileceği konusunda bildiri yayımlamıştır31. Yapay zekayla ilgili kaygı duyulmasının en önemli sebebinin, makinelerin gerek anlamda motivasyona ve iradeye sahip olduklarında, onların motivasyonlarını anlayamayacak ve kararlarını tahmin edemeyecek olmamız olduğu belirtilmektedir32. Bilişim teknolojilerinin tehlikeli yeteneklerin gelişmesine neden olması da söz konusudur. OpenAI’nin Üst Yöneticisi (CEO) Samuel Harris Altman, en büyük korkusunun, teknoloji endüstrisi olarak dünyaya önemli zararlar verme ihtimali olduğunu belirtmektedir. Bunun birçok farklı şekilde olabileceğini, çok kötü yerlere gidebileceğini düşündüğünü belirtmiştir33. Yapay zeka teknolojilerinin lisans denetimlerini yapacak bağımsız bir mekanizmanın kurulması tavsiyesinde bulunmuş ve bu sayede, tehlikeli yeteneklerinin değerlendirilmesi dahil bir dizi güvenlik standardının oluşturulabileceğini dile getirmiştir34. Altman, bu şekilde modellerin “kendi leri Tespit Etmeye ve Önlemeye Nasıl Yardımcı Oluyor?”, <https://ts2.space/tr/yapay-zekave-siber-suclari-onleme-akilli-sistemler-siber-tehditleri-tespit-etmeye-ve-onlemeye-nasilyardimci-oluyor/>, Erişim Tarihi 4 Ağustos 2023. 30 <https://tr.wikipedia.org/wiki/Yapay_zek%C3%A2>, Erişim Tarihi 1 Ağustos 2023. <BR> 31 <ttps://www.diken.com.tr/uzmanlardan-yapay-zeka-bildirisi-insanligi-yok-edebilir/>, Erişim Tarihi 1 Ağustos 2023. 32 Mehtap Doğan, “Yapay Zekâ ve Özgür İrade: Yapay Özgür İradenin İmkânı”, TRTakademi, 6(13), 2021, s. 791. 33 İngiltere Başbakanı Rishi Sunak’ın teknoloji danışmanı Matt Clifford, yapay zekayla ilgili pek çok farklı risk türü olduğuna dikkat çekerek, “Sektörde genellikle yakın ve uzun vadeli risklerden bahsedildiğini ve yakın vadeli risklerin aslında oldukça korkutucu olduğunu, yapay zekanın, bugün biyolojik silahlar için yeni tarifler oluşturmak veya büyük ölçekli siber saldırılar başlatmak için kullanabileceğini, insanlığın yapay zeka tarafından yok edilme ihtimalinin sıfır olmadığını, odaklanılması gereken şeyin, bu modellerin nasıl kontrol edileceğini bildiğimizden nasıl emin olunacağı olduğunu ifade etmektedir: <https:// <BR>www.mynet.com/uzmanlardan-yapay-zekalar-hakkinda-korkutan-uyari-en-gec-iki-yil<BR>icerisinde-110107132576>, Erişim Tarihi 1 Ağustos 2023. 34 ABD tarafındanyapılan açıklamada, yapay zekanın zamanın en güçlü teknolojilerinden biri olduğunu ancak sunduğu fırsatları değerlendirmek için önce risklerinin azaltılması gerektiği kendini kopyalayıp çoğalamayacaklarından ve kendi başlarına hareket edemeyeceklerinden” emin olunabileceğini belirtmiştir35. Bazı yazarlarlar ise, insanlığı kurtarabilecek 2 seçeneğin olduğunu, bulardan birinin yapay zekâyı kodlayan insanların ahlaki kapsamlılığını geliştirmek, ikincisinin ise yapay zekâyı, çoğu insanın yapabileceğinden çok daha yüksek bir ahlaki kodla çalışacak şekilde kodlamak olduğunu belirtmektedirler. Bunları yaptıktan sora yapay zekâyı kendisini kodlayacak şekilde yetkilendirmek gerektiğini ifade etmektedirler36. Ancak bazı uzmalar tarafından tehlike olmadığı, yapay zekaya önyargıyla yaklaşıldığı da belirtilmektedir37. E. Yapay Zekanın Kullanım Alanları ve Suç İşlemedeki ve Önlemedeki Etkileri Yapay zekanın pek çok kullanım alanı bulunmaktadır. Bunlardan biri görüntü işleme (yüz tanıma, güvenlik ve gözetleme, sosyal ağlarda fotoğraf etiketleme, spor analitiği ve strateji optimizasyonu, sentetik görüntü üretimi), diğeri ses işleme (müzik tanıma, sesli asistanlar, sesli yanıt ve şifre, konuşmadan metin sentezi, metinden konuşma sentezi), bir diğeri metin işleme (çeviri servisleri, çevrimiçi sohbet ve asistan, sosyal medya analitiği ve duygu durum analizi, kişiye özgü yazım düzeltme ve öneri), bir diğeri veri işleme (öneri sistemleri, ilan öneri, müzik öneri, müşteri deneyimi ve müşteriler için akıllı kampanya önerisi, hava durumu, trafik yoğunluğu gözeterek rota planlama, periyodik bakım ve onarım kestirimi, işe alım ve performans değerlendirme sistemleri, oyun motorları), bir diğeri sağlık verilerinin analizi ve tedavi planlaması (tanı koyma ve tedavi planlama sürecinde doktorlara yardımcı olan uygulamalar), bir diğeri insansız -yz destekli sürüş sistemleri (otonom araçlarda karar destek sistemleri), bir diğeri sigortacılık ve finans (sanal asistanlar, hasar yönetimi, sahtekârlık tespiti ve önleme, anomali tespit uygulamaları), bir diğeri büyük veri analitiği (büyük veri analizi ile davranış analizi), bir diğeri tarım ve hayvancılıkta akıllı uygulamalar (insansız hava aracı (iha) ile görüntü kaydedilerek, 7 yapay zeka araştırmaenstitüsü kurulması için harekete geçildiği bildirilmiştir: <https://www.haberturk.com/abd-7-yapay-zeka-enstitusu-kuruyor-3588997-teknoloji>, Erişim Tarihi 23 Temmuz 2023. 35 https://www.mynet.com/chatgpt-yi-gelistiren-openai-in-ceo-su-samuel-harris-altman-enbuyuk-korkum-110107125715, Erişim Tarihi 23 Temmuz 2023. 36Bu görüş içi bkz.: Koray Doğan, “Sürücüsüz Araçlar, Robotik Cerrahi, Endüstriyel Robot lar ve Cezai sorumluluk”, D.E.Ü. Hukuk Fakültesi Dergisi, Prof. Dr. Durmuş TEZCAN’a Armağan, 21(Özel S.), 2019, s. 3236. 37 <https://www.diken.com.tr/uzmanlardan-yapay-zeka-bildirisi-insanligi-yok-edebilir/>, Erişim Tarihi 1 Ağustos 2023. işleme temelli hassas tarım uygulamaları, hassas hayvansal üretim),bir diğeri siber güvenlik (siber saldırıları tespit ve engelleme için uzman sistem, kötücül yazılım analizi)38, bir diğeri makale yazma, bir diğeri regresyon analizi <BR>(geçmiş verilere dayanılarak bir değişkenin gelecekteki değerinin tahmin edilmesi, ekonomik öngörüler, üretim miktarı öngörüleri gibi), bir diğeri ise önerici sistemler (kullanıcıların geçmiş davranışlarına dayanarak yeni içerik önerilmesidir. Sosyal medya sitelerinde yeni arkadaş, mağazalarda başka bir ürün, gazetede başka bir haber önerileri gibi) olarak ifade edilebilir39. Yapay zekanın yakın gelecekte, birbirleri ile konuşabilecekleri (bilgi protokolleri), aynı amaca yönelebilecekleri (amaç/sensör modellemesi), sosyalleşebilecekleri, yardımlaşabilecekleri, birbirlerine destek üretebilecekleri (duygusal zekâ), birbirlerine olayları öğretebilecekleri (zeki öğretim sistemleri), ARGE çalışmaları yapabilecekleri ve inovatif davranabilecekler (bilimsel keşiflerin modellenmesi), birden fazla işi tek başlarına yapabilecekleri (zeki etmenler), işletmelerin yönetim kademelerinde görev alabilecekleri ve sanal yöneticiler olarak hizmet verebilecekleri (zeki etmenler), kişiselleştirilmiş eğitim/öğretim sistemleri oluşturabileceklerdir (zeki öğretim sistemleri), muhatabı ile ana dili üzerinden iletişim kurma konusunda çok maharetli olabilecekleri (doğal dil işleme) ifade edilmektedir. Bu konuların çoğunda halihazırda çok fazla sayıda örnek bilimsel çalışmanın yapıldığı, bazılarının pratik uygulamalarının da görülmeye başlandığı, hatta robotların artıkdoktorluk yapabileceklerine yönelik araştırmaların bulunduğu belirtilmektedir40. Yapay zeka teknolojisinde yaşanan gelişmeler insan hayatını yukarıda belirtildiği gibi olumlu yönde etkilediği gibi ceza hukukunu da olumsuz olarak, suç işlemede kullanılmasıyla etkilemektedir. Bilişim alanında suç işleyenler saldırı aşamalarının hemen hemen hepsinde yapay zekadan faydalanmaktadırlar. Hedefin belirlenmesi için yapılan keşif aşamasında yapay zekâ tabanlı açık kaynak istihbarat uygulamalarının kullanımının yaygın olduğu görülmektedir. İnternette erişime açık tüm bilgileri tarayarak hedef hakkında veri toplayan web tabanlı uygulamalar ve hedefin tespitinden sonraki aşamada kullanılan araçlar mevcuttur. Örneğin derin öğrenme (Deep Learning) ve Zafiyet Sömürme (Exploit) teknolojilerini kullanan DeepExploit 38 <https://cbddo.gov.tr/sss/yapay-zeka/>, Erişim Tarihi 2 Ağustos 2023. <BR>39 <https://tr.wikipedia.org/wiki/Yapay_zekâ>, Erişim Tarihi 5 Ağustos 2023. <BR> 40 Öztemel, s. 103, 104. isimli uygulama, bir ağda zafiyet tespit etme ve sömürme konusunda uzmanlaşmış bir yazılımdır. Hedef ağı otomatik olarak tarama yapmakta, zafiyetleri tespit etmekte ve ardından tespit edilen zafiyetlere otomatik olarak bir dizi exploit (zararlı yazılım kullanarak yetkisiz erişim sağlama) deneyebilmektedir41. Uzmanlar, yapay zekanın yepyeni iş alanları açarken, bazı işlerin de otomatikleşmesine neden olacağını belirtmektedirler. Var olan pek çok mesleğin çok yakın bir gelecekte makineler tarafından yapılacağı düşünülmektedir42. Yapay zekâ ve yapay zekalı varlıklar, kişilerin hayat, vücut dokunulmazlığı, özel yaşamın gizliliği, kişisel veriler, şeref, malvarlığı gibi kişisel değerlerin ihlâl edilmesini, bilişim suçlarının işlenmesini sağlayabilmektedir. Örneğin askerî amaçlı yapay zekânın, yaşam hakkına, vücut bütünlüğüne zarar vermesi söz konusu olabilecektir. Aynı şekilde tıbbî amaçla kullanılan yapay zekalar, daha sonra ayrı başlık altında ifade edeceğimiz otonom araçlar, yaşam hakkına ve vücut dokunulmazlığına zarar verebilmektedir. Yine bir drone’un yahut algılayıcı yapay zekâ sisteminin kaydettiği veriler özel hayatın gizliliğini ihlal edebilecektir. Keza elektronik alışverişte yahut bankacılık sektöründe kullanılan yapay zekânın kişisel verileri ifşa etmesi özel hayatın gizliliğini ihlal edebilecektir43. Yapay zekâ algoritmaları ile ses taklidi yapılabilir ve mevcut olmayan resimler oluşturulabilmek suretiyle suç işlemede kullanılabilir. Bu suretle dolandırıcılık, hakaret, özel hayatın gizliliği, müstehcenlik, iftira, tehdit, şantaj gibi suçlar işlenebilir. E-posta hesaplarının kullanıcı adlarının ve şifrelerinin tahmin edilmesinde yapay zekâ algoritmaları kullanılarak kişisel verilerin ele geçirilmesi mümkün olabilmektedir. Fidye yazılımlarının daha hızlı ve daha etkili bir şekilde yayılmasında yapay zekâ teknolojileri kullanılmakta, dolayısıyla da daha fazla sisteme bulaşması sağlanabilmekte, daha hızlı bir şekilde para talep edilebilmekte ve fidye ödemesinin izlerinin silinmesi sağlanabilmektedir. Yine suçlular yapay zekâ içeren uygulamalar ile sahte web siteleri ve e-postalar gibi kimlik avı saldırılarında kullanılan daha başarılı içerikler üretebilmekte, bu sayede hedef kişilerin daha fazla kişisel bilgi vermeleri veya kötü amaçlı yazılım yüklemeleri daha kolay 41 Murat Osman Kandır, “Yapay Zekanın Siber Suçlardaki Rolü”, Hukuk ve Bilişim 3. Nesil Hukuk Dergisi, <https://www.hukukvebilisimdergisi.com/yapay-zekanin-siber-suclardaki<BR> rolu/>, Erişim Tarihi 30 Temmuz 2023. 42 Çağla Üren, “Yapay Zeka İşinizi Ne Zaman Elinizden Alacak: 10 Sektörden Tahminler”, <https://www.indyturk.com/node/646156/bı̇lı̇m/yapay-zeka-işinizi-ne-zaman-elinizdenalacak-10-sektörden-tahminler>, Erişim Tarihi 30 Temmuz 2023. 43 Akkurt, s. 43, 44. gerçekleştirilmektedir. Dolayısıyla kişisel verilerin ele geçirilmesi, bilişim sistemine hukuka aykırı girme, sistemi engelleme, bozma, verileri yok etme veya değiştirme suçu işlenebilmektedir. Yine bilişim suçlarının işlemesinde kullanılan kötücül yazılımların güvenlik yazılımları tarafından tespit edilmeyecek şekilde geliştirilmesinde eğitilebilen yapay zekâ algoritmaları kullanılmaktadır. Oluşturulan kötü amaçlı yazılımların etkin bir şekilde geniş kitlelere yayılmasında da yapay zekanın kullanılması etkili olmaktadır. Bilişim suçlarının işlemesinde kullanılan DDoS saldırılarında yapay zekâ destekli uygulamalar hem hedef tespitinde hem de hedefe farklı IP adreslerinden iletişim trafiği oluşturmada yararlanılmaktadır. Yeterli güvenlik önlemleri alınmadan muhafaza edilen veriler yapay zekâ kullanılarak geliştirilen tarama uygulamaları tarafından tespit edilmekte ve yetkisiz erişim sağlanarak ele geçirilmektedir. Dolayısıyla bilişim sistemine hukuka aykırı girme ve kişisel verilerin ele geçirilmesi suçu işlenebilmektedir44. Yapay zekaya karşı gerçekleştirilen bazı davranışlar da ileride ceza hukukunu etkileyebilecektir. Yapay zekâya karşı yapılan hakaret niteliği taşıyan fiiller, yaralama, mobbing gibi davranışlar ceza hukukuna ilişkin sorun olarak karşımıza çıkacaktır45. Yapay zeka konusunda teknolojide yaşanan gelişmeler ve dolayısıyla da ceza hukuku doktrininde ifade edilen teorik ve kavramsal belirlemeler, makineler için ceza hukuku oluşturulması fikrinin ileri sürülmesi sonucunu doğurmuştur46. Yapay zekanın suçları işlemede etkisi olduğu gibi suçlarla mücadelede de etkileri olmaktadır. Bir çok kurum ve polis teşkilatları yapay zeka teknolojisinden yararlanmaktadırlar. Farklı algoritmalar kullanarak, makine öğrenimi ve veri analizi yoluyla, çok büyük miktarda verileri büyük bir hızla analiz edebildiği ve sonuçlar çıkarabildiği için yapay zeka, sistemlerin güvenliğinde ve suçluların tespitinde kullanılmaktadır. Yapay zeka tabanlı çözümler, makine öğrenimi ve tahmine dayalı analitikten yararlanarak çok büyük miktarda ve türde veriyi analiz edebilmekte, kalıpları ve anormallikleri 44 Kandır,<https://www.hukukvebilisimdergisi.com/yapay-zekanin-siber-suclardaki-rolu/> Erişim Tarihi 30 Temmuz 2023 45 Etik açıdan ortaya çıkan ve çıkacak prolemler için bkz.: Okuyucu-Ergün, s. 742 vd. 46 Sascha Ziemann, “Wesen Wesen, seid’s gewesen? Zur Diskussion über ein Sttrafrecht für Maschinen”, Robotik und Gesetzgebung, (Hrsg.: Eric Hilgendorf/Jan-Philipp Günther), Ba den-Baden, 2013, s. 183 tanıyabilmekte ve hassas ve hızlı yanıt verebilmektedir47. Güvenlik açıklarını bulmak için yapay zekâ algoritmaları ile sistemde zafiyet taraması yapılmakta, zararlı yazılımları tespit etmek ve önlem almak amacıyla zararlı yazılımların diğer uygulamalardan ayırt edilmesi ve bu yazılımlara karşı önlem alınması kapsamında yapay zekâ teknolojisinden faydalanılmaktadır. Hemen hemen tüm e-posta uygulamaları istenmeyen (spam) e-postaların tespit edilmesinde yapay zekâ algoritmalarını yaygın olarak kullanmaktadırlar. Suçluların tespitinde yapay zekadan faydalanılmakta, yüz tanıma özelliği olan tüm teknolojilerde mutlaka yapay zekâ algoritmaları bulunmaktadır. Amerika’da meydana gelen bir olayda polis araba hırsızlığı olayına karışan bir kadının kamera kayıtlarından ulaştığı yüzünü DataWorks Plus adlı bir yüz tanıma aracına yüklemiş, yapay zeka aramayı tamamlayınca Woodruff’un adlı 8 aylık hamile ve 32 yaşındaki siyahi bir kişinin ismini vermiş, bu kişi daha sonra tutuklanmıştır. Yapay zeka bu sonuca varırken Woodruff’un sisteme kayıtlı 8 yaşındaki fotoğrafını kullanmış ve yanlış sonuca ulaşmıştır. ABD’de yüz tanıma sisteminin kullanılmasıyla haksız uygulamalara neden olunan başka olaylar da bulunmaktadır48. Bankacılık sektöründe yasal olmayan bir işlemin tespit edilmesinde yapay zeka kullanılmakta, yapılan işlemler sonucunda ortaya çıkan verinin üzerinde anomali araştırması yaparak normal dışı işlemleri tespit etmektedir. Yine veri depolama sistemlerinde veriler üzerinde kullanıcıların yaptığı her türlü işlem titizlikle izlenmekte ve akıllı uygulamalar ile normal dışı işlemler tespit edilerek verilerin korunması sağlanmaktadır. Yapay zekâ destekli antivirüs uygulamaları zararlı yazılımların kodlarını inceleyerek eğitilmekte, böylece daha önceden tespit edilmeyen virüs benzeri zararlı yazılımlar, eğitilmiş olan yapay zekâ tarafından fark edilmektedir49. 47 Frąckiewicz, <https://ts2.space/tr/yapay-zeka-ve-siber-suclari-onleme-akilli-sistemler-siber<BR> tehditleri-tespit-etmeye-ve-onlemeye-nasil-yardimci-oluyor/> Erişim Tarihi 30 Temmuz 2023. 48 2019’da yapılan bir araştırmada, birçok yüz tanıma algoritmasının ırksal azınlıkları yanlış tanımlama olasılığının beyaz insanlardan çok daha yüksek olduğunu ortaya çıkarmıştır. Ayrıntılı bilgi için bkz.: <https://edition.cnn.com/2023/08/07/us/detroit-facial-recogniti<BR>on-technology-false-arrest-lawsuit/index.html.>; <https://www.washingtonpost.com/na<BR>tion/2023/08/07/michigan-porcha-woodruff-arrest-facial-recognition/>, Erişim Tarihi 31 Temmuz 2023. 49 Kandır,<https://www.hukukvebilisimdergisi.com/yapay-zekanin-siber-suclardaki-rolu/>, Erişim Tarihi 30 Temmuz 2023. F. Bazı Yapay Zeka Teknolojileri Üretken yapay zeka, yeni, orijinal içerik oluşturmaktan sorumlu bir yapay zeka (AI) türüdür. İnsan müdahalesine gerek kalmadan görüntü, video, müzik gibi içerikler üretmek için algoritmalar kullanmaktadır50. Derin sinir ağlarından ve gelişmiş algoritmalardan yararlanarak geniş veri kümelerinden öğrenebilmekte ve yaratıcılık ve özgünlük sergileyen çıktılar üretebilmektedir. Sanat, eğlence, oyun, moda, reklamcılık gibi bir çok alanda kullanılmaktadır. Ancak aynı zamanda kötüye kullanılması sonucunu da doğurmaktadır. İkna edici ve gerçekçi içerik üretme sayesinde yasal olmayan amaçlar için kullanılmaktadır51. Deepfake teknolojisiyle52 oluşturulan içeriklerle kişiler hiç söylemediği ya da hiç yapmadığı şeylerden sorumlu tutulabilirler. Bu suretle dolandırıcılık, hakaret, özel hayatın gizliliği, müstehcenlik, iftira, tehdit, şantaj, bilişim alanında suçlar, kişisel verileri hukuka aykırı olarak verme veya ele geçirme, suç işlemeye tahrik gibi fiillerişlenebilir 53.Örneğin, 2019 yılında Malezya’da bir kabine bakanıyla yardımcısının eşcinsel ilişkileri olduğunu gösteren deepfake teknolojisiyle oluşturulmuş sahte bir video yayımlanmıştır. Yine 2020 yılında, Rus Genelkurmay başkanı Leonid Volkov’un sahte görüntüsü ve sesi kullanılarak Letonya Parlamentosu Dış İlişkiler Komitesi başkanı Rihards Kols ile çevrimiçi görüşmeler yaptığı yayımlamıştır54. 50 <https://sonix.ai/resources/tr/uretken-ai-ne-dir/>, Erişim Tarihi: 30 Temmuz 2023. <BR> 51 “Üretken yapay zeka kavramı, insan tarafından oluşturulan içeriğe çok benzeyen görüntüler, metinler, müzik ve hatta tüm sanal dünyalar gibi yeni içerikler üretmek için makine öğrenimi modellerinin eğitilmesi etrafında dönüyor”, Yapay Zeka ve Veri Bilimi, Hukuk ve Bilişim Pazar Bülteni, s. 68, <https://www.linkedin.com/pulse/hukuk-ve-bilişim-pazar-bülteni-sayı<BR>68-hukuk-ve-bilişim-dergisi/> Erişim Tarihi 27 Temmuz 2023. 52 “Deepfake İngilizce’de deep (derin) ve fake (sahte) kelimelerinin bir araya gelmesinden oluşur. Teknolojinin gelişmesiyle birlikte gerçeklik algısını derinden etkileyen deepfake, herhangi bir kişiyi aslında bulunmadığı video ya da fotoğraflara eklemeye denir”, <https://berq<BR>net.com/blog/deepfake.> Erişim Tarihi: 28.7.2023 Ayrıca bkz.: <https://www.webtekno.com/ <BR>deepfake-videolar-ilk-kez-suc-sayilacak-h130058.html#:~:text=Yeni%20yasayla%20bir<BR>likte%20bir%20ki%C5%9Finin,olu%C5%9Fturan%20ki%C5%9Filer%2C%20hapis%20 <BR>cezas%C4%B1yla%20kar%C5%9F%C4%B1la%C5%9Facaklar>, Erişim Tarihi 29 Temmuz 2023. 53 “Deepfake, mevcut bir görüntü veya videoda yer alan bir kişinin,yapay sinir ağlarıkullanarak bir başka kişinin görüntüsü ile değiştirildiği bir medya türüdür. Sıklıkla, otomatik kodlayıcılar ve üretken çekişmeli ağlar (GAN’lar) olarak bilinen <BR>makine öğrenme <BR>tekniklerini kullanarak mevcut medyanın kaynak medya üzerinde birleştirilmesi ve üst üste konması ile üretilirler”, <https://tr.wikipedia.org/wiki/Deepfake>, Erişim Tarihi 29 Temmuz 2023. 54 Buket Abanoz Öztürk, “Derin Sahte (Deepfake) Teknoloji Karşısında Türk Ceza Hukuku”, ChatGPT55’56, Google Bard57, Bing Chat’de58’59 ihlallere neden Yapay Zekâ Temellı̇ Teknolojı̇ler ve Ceza Hukuku, Yapay Zekâ Çalışma Grubu, Yıllık Rapor, 2021, <https://www.istanbulbarosu.org.tr/files/komisyonlar/yzcg/2021yzcgyillikrapor.pdf>, Erişim Tarihi 31 Temmuz 2023, s. 66, 67. 55 Yapay zeka destekli sohbet robotudur. Robot, kendisine sorduğunuz soruları karşınızda bir insan varmış gibi cevaplayabilmekte, hangi dilde yazdığınızı anlayabilmekte, kullanıcısı için istediğinde açıklayıcı yazılar oluşturabilmekte, farklı programlama dillerinde programlar yazabilmekte ve hataları dahi ayıklayabilmektedirhttps://bilimgenc.tubitak.gov.tr/makale/ chatgpt-nedir-nasil-kullanilir, Erişim Tarihi 26 Temmuz 2023. 56 “OpenAI, 2022’nin sonbaharında, şirketin GPT-3 modeline dayanan <BR>ChatGPT <BR>[4] <BR>sohbet botunu başlattı. ChatGPT, şu anda mevcut olan en gelişmiş sohbet botlarından biri olarak kabul edilir ve konuşma tabanlı yapay zeka geliştirme sürecinde önemli bir kilometre taşı olarak görülür. Model, büyük miktarda insan konuşmasıyla eğitildiği için kullanıcılarla doğal ve insan gibi iletişim kurabilir”, <https://tr.wikipedia.org/wiki/Sohbet_botu> Erişim Tarihi 26 Temmuz 2023. 57 Google’ın ChatGPT’yi potansiyel bir tehdit olarak görmesi ile bir proje başlatıp Bard Projesini ortaya çıkarmışlardır. Google’a ait olan LaMDAdil ailesini kullanan Brad, piyasaya Sürüldü. Bard, ChatGPT’ye benzer şekilde çalışan bir Google yapay zeka sohbet robotudur. Kullanıcılar chatbot ile konuşarak bilgi alabilmektedirler: <https://www.hosting.com.tr/blog/ <BR>bing-chat/#>, Erişim Tarihi 27 Temmuz 2023. 58 Microsoft’un Bing Chat’i oldukça akıllı olup, içeriği anlayabilmekte, geçmiş konuşmaları hatırlamakta ve internete tam erişime sahip bulunmaktadır. Bing Chat’ten bir sonraki seyahatiniz için bir seyahat programı planlamasını veya sıkıcı bir mali raporu özetleyip başka bir şeyle karşılaştırmasını yapabilmeniz mümkündür: https://www.hosting.com.tr/blog/bing<BR>chat/#. kişiselleştirilmiş bir sanal asistandır. “Bing Chat AI kişisel asistanı, doğal dil sorgularını anlamak ve kullanıcılarla dinamik konuşmalar yapmak üzere tasarlanmıştır. Gelişmiş makine öğrenimi algoritmalarından yararlanarak karmaşık soruları yorumlayabilir, ilgili yanıtlar verebilir ve hatta kullanıcının tercihlerine ve arama geçmişine göre ek bağlam sunabilir. Bu akıllı asistan, arama sürecini kolaylaştırmayı ve daha doğru ve kişiselleştirilmiş sonuçlar sunmayı amaçlıyor. Bing Chat AI’nin en önemli özelliklerinden biri, bağlamsal konuşmalara katılma yeteneğidir. Kullanıcılar takip soruları sorabilir, sorgularını netleştirebilir veya ek bilgi sağlayabilir ve sanal asistan yanıtlarını buna göre dinamik olarak ayarlayacaktır. Bu diyaloğa dayalı yaklaşım, daha insani bir etkileşim yaratarak kullanıcıların ihtiyaç duydukları bilgileri bulmalarını kolaylaştırıyor... Bing Chat AI, makine öğrenimi ve doğal dil işlemenin gücünden yararlanarak yeni bir arama ve sanal yardım çağına zemin hazırlıyor”, Yapay Zeka ve Veri Bilimi, Hukuk ve Bilişim -Pazar Bülteni, S. 68,< https://www.linkedin. <BR>com/pulse/hukuk-ve-bilişim-pazar-bülteni-sayı-68-hukuk-ve-bilişim-dergisi/>, Erişim Tarihi 27 Temmuz 2023. 59 Samsung, JP Morgan ve Goldman Sachs gibi şirketlerin izinden giden Apple, şimdi de iş gücü arasında ChatGPT, Bard ve Bing gibi yapay zeka destekli sohbet robotlarının kullanımını yasaklama kararı almıştır. Hareketin, Apple’ın hassas verilerin yanlışlıkla ifşa edilmesini önleme çabasının bir parçası ve aynı zamanda şirketin kendi içinde benzer bir teknoloji yaratma planlarıyla çeliştiği belirtilmektedir: <https://hwp.com.tr/apple-chatgptyi<BR>yasakladi-242920>, Erişim Tarihi 25 Temmuz 2023. olacak uygulamalardır60’61. Hassas verilerin ifşasına neden olması, kişisel verilerin korunmasının ihlaline neden olması (kişisel verilerin toplanması, depolanmasına sebebiyet vermesi, dolayısıyla da elde edilen bu bilgilerin dolandırıcılıkta, bilişim suçlarının işlenmesinde kullanılması), aldatıcı nitelikte sonuçlar üretmeleri, çocukların gelişiminde olumsuz sonuçlara neden olması, verilerin ele geçirilmesi neden olmaları, siber saldırılarda kullanılmaları nedeniyle kamu güvenliği açısından risk oluşturmaktadırlar62. Nitekim ChatGPT’yeİtalyamakamları tarafından yasak getirilmiştir63. Ayrıca 60 OpenAI şirketinin en yeni GPT modeli olan GPT-4’ün “aldatıcı, mahremiyet ve kamu güvenliği için risk oluşturduğu” gerekesiyle Yapay Zeka ve Dijital Politika Merkezi (CAIDP) Federal Ticaret Komisyonu’na (FTC), şirketin yapay zeka ürünlerinin FTC’nin kılavuzundaki “şeffaf, açık ve hesap verebilirlik” standartlarını karşılamadığını belirterek kullanımının durdurulması talebinde bulunmuştur: <https://www.mynet.com/ <BR>kullaniminin-durdurulmasi-talebinde-bulundular-abd-de-sok-cagri-110107111222>, Erişim Tarihi 25 Temmuz 2023. 61 Bill Gates, Linkedin hesabından yaptığı açıklamada yapay zeka çağının başladığını belirtmiştir. “Yapay Zeka Çağı Başladı” başlıklı bir makale yayımlayarak (https://tr.linkedin. com/pulse/bill-gates-yapay-zeka-%C3%A7a%C4%9F%C4%B1-ba%C5%9Flad%C4%B1faruk-can) eşitsizliklerin azalacağını ve bu gelişmenin bir çok soruna çözüm olacağını belirtmiştir. Gates, yapay zekanın kullanıma girmesinin, “Mikroişlemcilerin, kişisel bilgisayarların, internetin ve cep telefonunun gündelik hayatımıza girmesiyle eşdeğer olduğunu” vurgulamıştır: https://artigercek.com/dunya/windowsun-yaraticisindan-chatgpt<BR>yorumu-yapay-zeka-cagi-basladi-243538h, Erişim Tarihi 25.07.2023. Yine Gates, yapay zeka projelerinin nihayetinde teknoloji devlerinin (Google gibi)sonunu getireceğini, beyaz yakalı ve mavi yakalı çalışanları etkileyeceğini, arama motorlarını ve alışveriş sitelerini yok edebileceğini, daha gelişmiş ilaç geliştirmeyi sağlayacağını iddia etmiştir. Ayrıca yapay zekanın gelişiminin bazı tehlikeli sonuçları olabileceğini de vurgulamaktadır: https:// <BR>www.turkiyegazetesi.com.tr/teknoloji/bill-gatesten-insanliga-yapay-zeka-uyarisi-buyuk<BR>sirketlerin-sonunu-getirecek-966600; https://www.ekonomist.com.tr/teknoloji/bill-gates<BR>ten-gelecekle-ilgili-3-ongoru-41445/5; <https://www.mynet.com/bill-gates-ten-yapay<BR>zekayla-ilgili-cok-konusulacak-aciklamalar-sonlarini-getirebilir-110107127956>, Erişim Tarihi 25 Temmuz 2023. 62 <https://www.tgrthaber.com.tr/teknoloji/apple-calisanlarina-chatgpt-yasaklandi<BR>neden-2888751.> Japonya’nın Hiroşima kentinde bir araya gelen G7 liderleri, yapay zekayı (AI) “güvenilir” tutmak için teknik standartların geliştirilmesi ve benimsenmesi çağrısında bulundu. Liderler, teknolojinin idaresinin büyüme hızıyla doğru orantılı olmadığını vurguladı. Dünyayı faydaları ve riskleri ile ikiye bölen yapay zeka (AI) teknolojisi için G7 liderleri de belirli önlemler alınması gerektiğini vurgulayan bir açıklama yapmışlardır. Japonya’nın Hiroşima kentinde bir araya gelen G7 liderleri, “güvenilir yapay zekanın ortak vizyonuna ve hedefine” ulaşma yaklaşımlarının değişebileceğini kabul ederken, bir açıklamada AI gibi dijital teknolojilerin kurallarının “ortak demokratik değerlerine uyumlu” olması gerektiğini belirttiler: <https://www.haberturk.com/g7-yapay-zeka-icin-kuresel-teknik-standartlar<BR>gelistirme-cagrisinda-bulundu-3593433-teknoloji>, Erişim Tarihi 1 Ağustos 2023. 63 İtalyan Veri Koruma Kurumu’ndan yapılan açıklamada, uygulamanın kullanıcı verilerine saygı göstermediği ve kullanıcıların yaşını doğrulayamadığı belirtilmiştir: <https://www. <BR>trthaber.com/haber/dunya/chatgpt-italyada-yasaklandi-757446.html>, Erişim Tarihi 25 ChatGPT kullananların bilgileri de hukuka aykırı erişim yapmak suretiyle çalınabilmekte, yapay zeka güvenliğini ortaya çıkarmaktadır64. Özellikle kötü niyetli faaliyetler için tasarlanmış, etik sınırları olmayan ChatGPT tarzı WormGPT’nin dark web’deki siber suç forumlarında pazarlandığı belirtilmektedir. Bu yapay zekanın, bilgisayar korsanlığı faaliyetlerinde kullanılabileceği, insan elinden çıkmışa benzeyen metinler üretebilen “sofistike bir yapay zeka modeli”olduğu, siber saldırılar, kötü amaçlı yazılım saldırıları için kod yazmak ve oltalama saldırıları için e-posta hazırlamak da dahil çeşitli hizmetleri gerçekleştirebildiği ifade edilmektedir. ChatGPT ve Google Bard’ün insanların bu teknolojiyi kötü amaçlarla suiistimal etmesini önleyen yerleşik korumalara sahip olduğu, buna karşılık WormGPT’nin suç faaliyetlerini kolaylaştırmak için tasarlandığı iddia edilmektedir65. II. CEZA HUKUKU SORUMLULUĞU A. Genel Olarak Yapay zekanın suç oluşturan eylemlerinden kimin sorumlu olacağı önemli bir sorun olarak karşımıza çıkmaktadır. Öncelikle yapay zekanın sorumlu olup olmayacağı tartışılmaktadır. Suçun Kıta Avrupa sisteminde gerçek kişiler tarafından işleneceğinin kabul edilmesi yapay zekanın kişi sayılıp sayılmayacağı tartışmasını ortaya çıkarmaktadır. Kişi sayılıp sayılmayacağı (gerçek kişi-tüzel kişi veya özel bir statü verilmesi -‘elektronik kişilik-insan olmaya kişi’), eşya mı kabul edileceği tartışılmaktadır66. Avrupa Parlamentosu 27 Ocak 2017 tarihli Robotikler Hakkında Medenî Hukuk Kuralları Tavsiye Raporunda ( Report with Recommendations to The Commission on Civil Law Rules on Robotics22) Temmuz 2023. 64 “Büyük bir güvenlik ihlali 100.000’den fazla ChatGPT kullanıcı hesabının çalınmasıyla sonuçlandı. Hackerlar, popüler yapay zeka destekli chatbot platformuna yetkisiz erişim sağlayarak kullanıcı adları, şifreler ve kişisel veriler dahil olmak üzere hassas kullanıcı bilgilerini tehlikeye attı. Olay, yapay zeka sistemlerinin güvenliği ve kullanıcı gizliliğinin korunması konusundaki endişeleri artırıyor”, <https://thehackernews.com/2023/06/over<BR>100000-stolen-chatgpt-account.html>, Erişim Tarihi 25 Temmuz 2023. 65 Anthony Cuthbertson, “Chatgpt’nin “Etik Sınırları Olmayan” Rakibi, Dark Web’de Satılıyor”,<https://www.indyturk.com/node/648406/yaşam/chatgptnin-etik-sınırları<BR>olmayan-rakibi-dark-webde-satılıyor>, Erişim Tarihi 23 Temmuz 2023. 66 Bkz.: Seda, Kara Kılıçarslan, “Yapay Zekanın Hukukı̇ Statüsü ve Hukukı̇ Kı̇şı̇lı̇ğı̇ Üzerı̇ne Tartışmalar”, YBHD, (2), 2019, s. 363-389, s. 377 vd.; Gökhan Erdoğan, “Yapay Zekâ Ve Hukukuna Genel Bı̇r Bakış”, AD, (66), 2021, s. 117-192, s. 169. “Elektronik kişi” kavramını ortaya atmıştır67. Elektronik kişi belirlemesiyle, yapay zekalı robotik sistemler eşya olmaktan çıkarılıp, haklara, borçlara ve belli bir malvarlığına sahip hukuk süjesi haline getirilmek istenmektedir. Böylece verdiği zararlarda sorumlu tutulmaları ve kusursuz sorumluluk yolunun da açılması hedeflenmektedir. Rapor yapay zekanın sicile kaydedilmesi ve tazminat gereken hallerde yapay zekaya özgü fona başvurulması gerektiğini ileri sürmektedir68. Günümüzde yapay zekanın bozulması ya da kontrolden çıkması halinde, sorumluluk üreticiye veya kullanıcıya ait kabul edilirken, rapordaki öneriye göre yapay zekanın öğrenme kapasitesinin ve özerkliğinin artmasıyla, sorumluluk giderek yapay zekaya yüklenecektir69. Doktrinde hukukun objesi olan eşya olarak mı kabul edileceği, kişilik mi tanınması gerektiği, yoksa kendine has özellikleri nedeniyle özel bir statüye mi kavuşturulması gerektiği tartışılmaktadır. Tüzel kişi kabul edilmesi ve tüzel kişilerdeki gibi uygulama yapılması gerektiği belirtilmektedir. Ancak tecrübe edinme ve öğrenme gibi yetilere sahip olduğundan tüzel kişilerden farklı olduğu belirtilmektedir70. Eşya kabul edilmesi yapay zekanın bilişsel özelliklere sahip olması nedeniyle itiraza uğramış, eşya olarak nitelendirilmesi gerektiğini belirten bazı yazarlar köle statüsünde değerlendirilmesi gerektiğini ileri sürmektedirler71. Bu görüşe göre, yapay zeka, ne kadar da insana özgü yetilerle donatılmış olursa olsun, hiçbir zaman bir insan olamayacaklardır. Dolayısıyla kölelik modeli kullanılarak hukuki kişilik reddedilmelidir72. Bazı yazarlar mal kabul edilmemesi, fikri mülkiyet çerçevesinde koruması gerektiğini belirtmektedirler. Bazı yazarlar tamamen kişiliktanınmasını kabul etmemektedirler73. Bazı yazarlar ise yapay zekalar için insan olmayan kişi belirlemesi yapılması gerektiğini savunmaktadırlar. Bu görüşe göre, insana özgü yetilere bu kadar yakın, ancak insan olmayan süjeler bakımından, yeni kişilik modellerinin önerilmesi gerekmektedir. İnsan olmadıkları için de beşeri varlıkları tanımlayan gerçek kişilere özgü hak statülerinin dışında 67 Bkz. Akkurt, s. 46, 47. 68 Kangal, s. 50; Kara Kılıçarslan, s. 382, 383. 69 Kara Kılıçarslan, s. 383. 70 Kangal, s. 47, 48; Kara Kılıçarslan, s. 381. 71 Yapay zeka ve kölelik ilişkisi içinbkz. Taşdemir/Özbay/Kireçtepe, s. 802 vd.; Mürvet Senem Çetin, “Yapay Zekanın Cezai Sorumluluğu”, İstanbul Barosu Dergisi, 95(5), 2021, s. 152, 153. 72 Kara Kılıçarslan, s. 378. 73 Ayrıntılı bilgi için bkz.: Kangal, s. 44 vd. bir kavramla hukuk süjesi olarak kabul edilmelidirler74. Yaşanan teknolojik gelişmeler, yapay zekaya kişilik tanınması yolunda ilerlemektedir75.Bu kişilik gerçek kişi ve tüzel kişilik olmayacaktır. Zira yapay zeka insan olmadığı için gerçek kişi sayılmayacak, tüzel kişilikten farklı özellikleri olduğu için (öğrenmesi, karar vermesi gibi) tüzel kişi olarak da kabul edilmeyecektir. Yapay zekanıniradi olarak hareket edebildiği kabul edildiğinde tüzel kişilerle aynı şekilde nitelendirilemeyecektir. Bu kişiliğin ne şekilde olacağını, neleri kapsayacağını teknolojik gelişmeler gösterecek ve zamanla yapılan tespitler değişiklik gösterecektir. Muhtemelen yapay zekaya özgü bir kişilik tanınması şeklinde olacaktır. Kişiliğin tanınmasının reddedilmesi teknolojik gelişmeler bu şekilde devam ettiği sürece zamanla anlamını yitirecektir. Yapay zekanın tamamen kontrolü ele geçirmesi durumunda ise onların belirleyeceği sistem geçerli olacaktır. B. Suçun Unsurları Açısından 1. Genel Olarak Yapay zekanın yaptığı şeyin hareket olarak nitelendirilip nitelendirilmeyeceği tartışılmaktadır. Hareketin varlığı için yapay zekanın robot76 veya bot olmasına göre ayrım yapılmaktadır. Robot kelimesi hem fiziksel varlığı olan robotları hem de sanal yazılım ajanlarını ifade etmektedir. Ancak robot denildiğinde fiziksel varlığı olan makineler anlaşılmakta, ikincisi genellikle bot olarak adlandırılmaktadır (robot yazılım). Robotun kısaltması olan “bot”, tekrarlayan, otomatik çalışan ve önceden tanımlanmış görevleri yerine getiren bir yazılım programıdır. Botlar genellikle insan kullanıcıların davranışlarını taklit eden veya onların yerini alan yapay zekaya sahip sanal 74 Kara Kılıçarslan, s. 381. 75 Kişilik kriterleri için bkz.: Kara Kılıçarslan, s. 373 vd. 76 Robot kavramı, ilk olarak 1920 yılında Çek yazar Karel Capek (kelimenin asıl mucidinin Karel’i kardeşi Josef Čapek olduğu belirtilmektedir) tarafından “R. U. R – Rossumovi Univerzální Roboti – Rossum’s Universal Robots” adlı tiyatro oyunu olan bir eserde kullanılmıştır: https://en.wikipedia.org/wiki/Robot. Hiçbir hakkı olmaksızın çalışan işçileri betimlemek için kullanılmıştır. Eserde robot-işçiler insanların iş yükünü hafifletmek amacı ile üretilmiştir: Ercan, s. 23. İlk modern dijital ve programlanabilir robot, 1954’te George Devol tarafından icat edilmiştir. Japonlar tarafından 1932’de ilk oyuncak robot üretilmiştir. Massachusetts Teknoloji Enstitüsü (MIT) 1940’ta cisimlerin insan olmadan algılanmasını içeren radar teknolojisini geliştirmiştir. George Devol, 1954’te programlanabilir genel amaçlı robotu tasarlamış, robot dünyasının Nobel’i sayılan <BR>Engelberger Ödülü’ne ismini veren Joseph F. Engelberger ile 1958’de ilk ticari robot üretilmiştir. NASA, 1997’de ‘Sojourner’ adını verdiği keşif robotunu Mars’a göndermiştir: “Robot Nedir”, <https://www.universal-robots. <BR>com/tr/blog/robot-nedir/,> Erişim Tarihi 1 Ağustos 2023. robotlardır. Otomatik oldukları için insan kullanıcılardan çok daha hızlı çalışmaktadırlar77. Robotun tanımlanması noktasında üzerinde uzlaşılmış bir tanım söz konusu değildir. 16 Şubat 2017 tarihli Robotikler Hakkında Medenî Hukuk Kuralları Tavsiye Raporu’nun C bendinde, robot ve yapay zekâ kavramlarına 77 İyi amaçlı kullanılabilmektedirler: “Arama motoru botları (“web böcekleri” veya “örümcek” olarak da bilinir). Bu botlar world wide web’i tarar ve web sitelerini Google, Yahoo ve Bing gibi arama motorlarının dizinlerine ekler. Sohbet botları. Bankalar, çevrimiçi satıcılar ve birçok web sitesi tarafından kullanılırlar. Sesli veya yazılı mesajlar ile gerçek bir insan ile konuşuyormuş izlenimi uyandırırlar. Sohbet botları, en çok müşteri desteği sağlamak için kullanılır ancak Discord sistem botu gibi daha gelişmiş örnekleri de vardır. İzleme botları. İsminden de belli olduğu üzere, bu botlar web sitenizin performansını kontrol etmek ve herhangi bir sorun çıkarsa raporlamak için kullanılır. Kişisel asistan botları. Siri ve Alexa bunların en iyi örneğidir. Normal botlardan çok daha gelişmiş özelliklere sahiptirler ancak aynı prensiplerle çalışırlar. Pazarlama botları. Pazarlama şirketleri tarafından reklamları ile müşteri incelemelerini takip etmek ve trend olan anahtar kelimeleri incelemek gibi amaçlarla kullanılırlar. İşletmelerin farklı metrikleri ölçerek gelirlerini artırmalarına yardımcı olan düzinelerce farklı çevrimiçi araç mevcuttur. Toplayıcı botlar. Bunlar çeşitli web sitelerinden bilgi toplar ve bu bilgileri belirli bir platformun haber akışına ekler (veya doğrudan kullanıcılara iletir). Örneğin medya kuruluşlarının haber bültenlerine abone olup önceden seçilen makalelerin bir kısmına her gün ulaşmanız mümkündü”, https://nordvpn.com/tr/blog/bot-nedir/. Kötü amaçlar için de yararlanılmaktadırlar: “1. Finansal ve kişisel bilgileri çalmak için Bilgisayar korsanları, tüketicileri paralarını vermeye ikna etmek için botnetleri kullanarak kimlik avı veya diğer dolandırıcılık girişimlerini gönderebilir. Ayrıca, bot bulaşmış makinelerden bilgi toplamak ve kimlik bilgilerini çalmak, kullanıcının adına kredi almak veya satın alma işlemleri gerçekleştirmek için kullanmak mümkün olabilir. 2. Yasal web hizmetlerine saldırmak için Suçlular botnetleri kullanarak yasal bir hizmeti veya ağı, yoğun trafik oluşturulan DoS ve DDoS saldırılarına maruz bırakabilir. Oluşturulan yoğunluk şirketin hizmetinin veya ağının yanıt verme yeteneğini ciddi şekilde yavaşlatabilir veya şirketin hizmetinin veya ağının tamamen kapanmasına neden olabilir. 3. Kurbanlardan para elde etmek Bir şirkete veya ağa zarar vermeyi amaçlayan gruplar DoS saldırıları aracılığıyla zorla (“ya ödeme yaparsın ya da siten çöker”) ya da dolaylı olarak gelir elde eder. Bu gruplar arasında siyasi gündemleri olan korsanların yanı sıra yabancı askeri ve istihbarat örgütleri de yer alır. 4. Zombi ve botnet sistemlerinden para kazanmak için Siber suçlular, botnetlerini spam göndermek, dolandırıcılık, kimlik avı, kimlik hırsızlığı yapmak için kullanabilir, hatta yasal web sitelerine ve ağlara saldırmak isteyen diğer suçlulara kiralayabilir”, <https://www.kaspersky.com.tr/resource-center/definitions/what-are-bots>, Erişim Tarihi 1 Ağustos 2023. ilişkin yapılacak tanımların, esnek olması ve bu alandaki gelişmeleri engellememesi gerektiği ifade edilmektedir78. Bir tanıma göre, “Biyolojik olarak canlı olmayan, üretilmiş ve fiziksel ve zihinsel özellikler gösteren şeye robot denir”79. Bir başka tanıma göre, otonom olarak görev yapan ve çoğu kez mobil (hareket edebilen) makineler robottur. Bir başka tanıma göre robot, “Hem fiziksel hem mental faaliyetlerde bulunmak üzere oluşturulmuş, biyolojik anlamda canlı olmayan sistemler”dir80. Birleşmiş Milletlerin 2005 tarihli Robot Bilim raporunda robot, “kısmen veya tamamen otonom olarak işleyen ya da yeniden programlanabilen makine” olarak tanımlanmıştır81. Avrupa Parlamentosunun 16 Şubat 2017 tarihli Robotikler Hakkında Medenî Hukuk Kuralları Tavsiye Paporunda, bir nesnenin robot olarak kabul edilebilmesi için sensörler yardımıyla ve/veya çevresi (içsel-bağlantı) ile veri değişimi sayesinde otonom özellik edinim ve bu verileri alıp-verme ve analiz edebilme, tecrübelerinden yararlanarak ve etkileşimle kendiliğinden öğrenme (opsiyonel kriter), en azından bir tali fiziksel destek, çevresel tutum ve hareketlere uyum sağlama, biyolojik yaşamın yokluğu kriterlerini taşıması gerekmektedir82. Bir başka tanıma göre, “fiziksel dünyada varlığı ve etkisi olan, çalışması için insanlarcaveya başka robot veya yapay zekâlı varlıklarca kontrol edilmesine ihtiyaç duymayan, üretilmiş, yapay zekâlı varlık” robot olarak nitelendirilmektedir83. TDK’ya göre robot, “Belirli bir işi yerine getirmek için manyetizma ile kendisine çeşitli işler yaptırılabilen otomatik araç”tır84.Robotlar yapay zekaya sahipse de, yapay zeka robot değildir. Yapay zeka robotu da içine alan üst bir kavramdır. Robotları, özellikle bilgisayar aracılığıyla programlanabilen, karmaşık bir dizi eylemi otomatik olarak gerçekleştirebilen bir makineler şeklinde tanımlayabiliriz. Genel olarak aşağıdaki yetenek ve işlevlerin bazılarına veya tümüne sahip olan makinelerin robot olarak kabul edildiği söylenebilir: Elektronik programlanabilen, verileri veya fiziksel algıları elektronik olarak işleyen, bir dereceye kadar otonom olarak çalışan, hareket eden, kendisinin fiziksel parçalarını veya fiziksel süreçleri çalıştıran, çevreyi algılayan ve manipüle eden ve özellikle 78 Ercan, s. 24. 79 Richards/Smart’ın tanımı için bkz.: Taşdemir/Özbay/Kireçtepe, s. 799. 80 Aksoy, s. 13. 81 Koray Doğan, Sürücüsüz Araçlar, s. 3224; Taşdemir/Özbay/Kireçtepe, s. 799. 82 Koray Doğan, Sürücüsüz Araçlar, s. 3224; Ercan, s. 25. 83 Taşdemir/Özbay/Kireçtepe, s. 799. 84 <https://sozluk.gov.tr>, Erişim Tarihi 1 Ağustos 2023. <BR> insanları veya hayvanları taklit eden davranışlar olmak üzere akıllı davranışlar sergileyen makineler85. Robotlar insan formunu çağrıştıracak şekilde inşa edilebileceği herhangi bir görüntüde de olabilir. Çoğu robot, etkileyici estetikten ziyade, işlevselliğe vurgu yapılarak tasarlanmış, görev ifa eden makineler niteliğindedir. Robotlar otonom veya yarı otonom olabilir. Çevresini sensörleri ile algılayan ve buna uygun karar verme kabiliyetine sahip robotlara otonom robot adı verilmektedir. Örneğin ev temizliğinde yerlerin silinmesi, süpürülmesinde kullanılması tasarlanan bir robot, faaliyet gösterdiği evin koordinatlarını kendi çıkarımları ile öğrenip ona uygun davranma kabiliyeti gösterebiliyorsa otonomdur. 16.02.2017 kabul tarihli Robotikler Hakkında Medenî Hukuk Kuralları Tavsiye Raporunda otonom olma, “karar verebilme ve bu kararları dış dünyada, dışarıdan bir yönlendirme veya etkileşim olmaksızın uygulayabilme kabiliyeti” olarak ifade edilmektedir. İnsan müdahalesinin olduğu durumlarda ise yarı otonom robottan söz edilmektedir86.Robotların, oyun oynayan insansı robotlar, endüstriyel robotlar, tıbbi ameliyat robotları, hasta yardım robotları, köpek terapi robotları, toplu olarak programlanmış sürü robotları, General Atomics MQ-1 Predator gibi İHAdronları, mikroskobik nano robotlar, mobil rotlar, eğitici robotlar, modüler robotlar, servis robotları, askeri robotlar, otonom araçlar, ev robotları gibi farklı türleri söz konusudur. Bir robot, gerçekçi bir görünümü taklit ederek ya da hareketleri otomatikleştirerek kendi zekasını ya da düşüncesini yansıtabilir87. Vernor Vinge, bilgisayarların ve robotların insanlardan daha akıllı olduğu bir anın gelebileceğini öne sürmüştür. Buna “Tekillik” adını vermektedir. Bunun insanlar için biraz ya da muhtemelen çok tehlikeli olabileceğini öne sürmektedir88. “ABD ordusu tarafından yapılan bir simülasyon testinde, yapay zeka tarafından yönetilen insansız hava aracının, “görevini tamamlamasını önlediği için” operatörünü öldürdüğü görüldü. ABD Hava Kuvvetleri’nin Yapay Zeka Testleri ve Operasyonları Müdürü Tucker ‘Cinco’ Hamilton, güçlü bir yapay zekanın kontrolündeki SİHA’ya “düşmanlarının hava savunma sistemlerini yok etme” emri verildiğini söyledi. Hamilton, SİHA’nın, simülasyonda emre karşı çıkan herkese saldırdığı belirtip, “Yapay zeka, hedefine ulaşmak için hiç beklenmeyen stratejiler kullandı” dedi. The Guardian’ın aktardığına 85 <https://en.wikipedia.org/wiki/Robot>, Erişim Tarihi 1 Ağustos 2023. <BR>86 Ercan, s. 26, 27. 87 <https://en.wikipedia.org/wiki/Robot>, Erişim Tarihi 1 Ağustos 2023. <BR>88 <https://en.wikipedia.org/wiki/Robot>, Erişim Tarihi 1 Ağustos 2023. <BR> göre, Hamilton, yapay zekanın görevini yerine getirdikçe puan kazandığını söyledi. Hamilton, bu yüzden simülasyonda SİHA’nın, “hedefi vurma” emri veren insan operatörü öldürdüğünün görüldüğünü belirtti. Hamilton, “Sistemi ‘Hey, operatörü öldürme, bu kötü bir şey, bunu yaparsan puan kaybedersin’ diye eğittik. O zaman o ne yaptı? Operatörün ‘hedefi vurma’emri vermesini önlemek için iletişim kulesini yıkmaya başladı” dedi.”89 2. Suçun Unsurları Açısından Bot’larda hareketin varlığının problemli olduğu, botların faaliyetini hareket olarak nitelendirmek için hareket kavramını bedensel niteliğinden arındırmak gerektiği, robotlarda ise hareketin irade ürünü olmasının sorun teşkil ettiği belirtilmektedir90. Nedensel hareket teorisi açısından yapay zekanın öğrenme yetileri bulunduğundan ve insan kontrolü dışında davranabildiklerinden iradi karar verebilecekleri ifade edilmektedir91. Sosyal hareket teorisi açısından, yapay zekanın ne yaptığının farkına varması ve bunun sosyal bakımdan önemli olduğunun farkında olması, yani potansiyel olarak diğer insanların hayatlarını etkilediğinin bilincinde olması gerektiğinden, şu an içinhareket yeteneğine sahip olmadığı belirtilmektedir. Bunu gerçekleştirdiğinde hareket yeteneğinden bahsedilebilecektir92. Kişisel hareket teorisi yönünden, yapay zekalarda ruhsal-zihinsel faaliyetin kontrolü93 olmadığından, yapay zekanın duyguları, istekleri, hayalleri bulunmadığından kişilik ortaya koymasının söz konusu olmadığı, dolayısıyla hareket yeteneklerinin bulunmadığı dile getirilmektedir94. Gai suç teorisi açısından, insanın amaca yönelik hareketini onun karakteristik özelliği olarak kabul edilmekte, dolayısıyla yapay zekanın hareketinin söz konusu olmayacağı, ancak fiziksel bir hareket, sadece belirli bir amaca ulaşmadan kaynaklanıyorsa, 89 <https://www.veryansintv.com/yapay-zekali-siha-operatorunu-oldurdu/https://www.veryansintv.com/yapay-zekali-siha-operatorunu-oldurdu/>, Erişim Tarihi 1 Ağustos 2023. 90 Farklı bilim dallarında hareket için bkz.: Dursun, Selman, Disiplinler Arası Bir Yaklaşımla Ceza Hukukunda Hareket Kavramı ve Terimi, Seçkin Yayıncılık, 2021, s. 37 vd. 91 Sabine Gless/ Thomas Weigend,“Intelligente Agenten und das Strafrecht”, ZSTW, 126(3), 2014, s. 571. 92 Sabine Gless, “Mein Auto fuhr zu schnell, nicht ich!’-StrafrechtlicheVerantwortung für hochautomatisiertes Fahren”, Intelligente Agenten und das Recht, (Hrsg.: Sabine Gless/ Kurt Seelmann), Baden-Baden, 2016, s. 244, 245. 93 Claus Roxin/ Luis Greco, Strafrecht, Allgemeiner Teil I, 5. Baskı, C.H. Beck, 2020, § 8, kn. 44, s. 355. 94 Kangal, s. 60. ceza hukukunun konusu olabileceği belirtilmektedir. Örneğin, kendi kendini süren bir aracın kavşağa yaklaşan araçları teşhis edebileceği ve durmamaya karar verebileceği ifade edilmektedir95. Bu çerçevede bazı yazarlar, yapay zekanın kendi iradesini oluşturma yeteneğine sahip olmadığından amaca uygun hareket etme yeteneğinin bulunmadığını, davranışları ile kararları arasında ahlaki diyologun kurulamayacağını ileri sürmektedirler96. Ancak bu teori kapsamında bazı yazarlar, yapay zekanın iradeye dayalı bir bilince sahip oldukları için amaca uygun hareket edebilmesi gerektiğini kabul etmektedir. Yazılımındaki ihtimalleri içeren dizilimler sayesinde somut olaya uygun hareketi seçebileceklerdir. İnsanlar da karşılarına çıkan çeşitli ihtimallere göre hareket ettiğinden yapay zeka da hareket yeteneğine sahiptir97. Bazı yazarlar yapay zekanın gelecekte kendi iradelerini şekillendirme kapasitesine sahip olacağını, ancak bir robotun karar verdiği farz edilse bile en azından bugün için kendi amaçlarını kararlaştırmasının mümkün olmadığını, bir robotun kendi hareketlerinin (bırakın ahlaki) sosyal sonuçlarının farkında olamayacağını belirtmektedirler98. Bazı yazarlar, yapay zekalı varlıkların gelişmişlik düzeyleri dikkate alındığında, günümüzde bir suçun doğrudan faili olarak kabul edilemeyecekleri, yapay zekanın teknolojisinin halen ‘Kendini Tanıyan Yapay Zekâ (Self-Awareness)’düzeyine ulaşamadığı, bu nedenle bir gün kendisini üreten, programlayan ve kullanan insanların iradesi dışında tamamen otonom şekilde hareket eden, hedefler koyan, insanların hükmedemediği, kendi kendine öğrenebilen, seçimler yapabilen, bunları uygulayabilen yapay zekâlı varlıkların ortaya çıkması halinde doğrudan cezai sorumluluklarının kabul edilebileceğini belirtmektedirler99. Bazı yazarlar ise, beşeri iradenin yapay zekada bulunmadığını, ancak insan davranışıyla kıyas yapılarak iradeyle gerçekleştirilmiş hareketten bahsetmenin mümkün olduğunu, insanın kurala uygun ve kuralla yönlendirilmiş olarak hareket ettiğini, yapay zekanın da programlama yoluyla iradi hareket etmesinin söz 95 Bu görüş için bkz.: Sabine Gless/Emily Silverman/Thomas Weigend, “Robotlar Zarara Ne den Oluyorsa, Kim Sorumlu Tutulabilir? Kendi Kendini Süren Arabalar ve Cezai Sorumlu luk”, (Çev.: Serkan Oğuz), Küresel Bakış, (23), 2017, s. 131. 96 Gless, s. 473. 97 Bkz.: Ramona Pormetter, “Fahrlassigkeitsstrafbarkeit im Zeitalter der Robotik”, Strafrecht und Moderne Technologien, Studien zum deutschen und türkischen Strafrecht, Band 5, (Hrsg.: Gunnar Duttge/Yener Ünver), Seçkin Yayıncılık, 2018, ss. 105-118, s. 109, s. 110; Kangal, s. 60, 61. 98 Gless/Silverman/Weigends, s. 132. 99 Aksoy, s. 20. konusu olduğunu belirterek yapay zekanın mutlak kuvvet dışında hareket yeteneklerinin bulunduğunu, robotlar bakımından ortaya çıkan hareket sorununun çözüm yapısının insan davranışıyla aynı olduğunu kabul etmektedir100. Bazı yazarlar, yapay zeka sisteminin teknik veya mekanik bir şey olduğunu ve şu anki iradi davranış gerektiren yasal uygulama karşısında kendi iradesini oluşturamayacağını, zira uygun veri setleri temelinde hareket ettiğini ve uygun eylem veya sonuçlar ortaya koyduğunu ifade etmektedir. Bu görüşe göre yapay zeka sistemi şu anda ceza hukukuna uygun olarak hareket edebilecek konumda değildir101.Yine bazı yazarlar da yapay zekanın da insan hareketiyle eşdeğer, hatta bunların üstüne çıkan hareketleri dış dünyada gerçekleştirebileceklerini ileri sürmektedirler102. Bazı yazarlar, yapay zekânın duyargaları aracılığıyla dış dünyadaki değişiklikleri algılayıp bunları yazılımındaki algoritmalar sayesinde değerlendirip belirli bir hedef doğrultusunda otonom olarak hareket ettiğini, dolayısıyla hareketinin iradi olup olmadığı, yapay zekânın davranışının onun yazılımından kaynaklanıp kaynaklanmadığına göre saptanması gerektiğini, yazılımı kırılmış (hacked) bir yapay zekâ söz konusu olduğunda ise, yapay zekânın kaybettiği/sahip olduğu otonominin derecesine göre yazılımını kıranın doğrudan veya dolaylı fail olarak sorumlu tutmanın düşünülebileceğini ifade etmektedir103. Bazı yazarlar ise, iradi hareket konusundan bağımsız olarak, hukuken önemli hareketin, sadece hukuk normlarının doğrudan hitap edebildiği kişilerin hareketi olduğunu, hukuk normlarını içerik olarak anlamayan kişilerin normun muhatabı olarak dikkate alınamayacağını, yapay zekaların normların emirlerini algılamalarının, anlamalarının ve tepkilerine dahil etmelerinin söz konusu olmadığını, hukuk normlarınıkendisi otonom şekilde kavramaksızın önceden kurulumu yapılmış programa göre hareket ettikleri için, yapay zekanın hukuken önemli hareket gerçekleştiremeyeceğini ifade etmektedirler104. Bazı yazarlar ise, yapay zekada olan hareketin tam anlamıyla insanda var olan iradi 100Bkz. Eric Hilgendorf, “Können Roboter schuldhaft handeln, Zur Übertragbarkeit unseres normativen Grundvokabulars auf Maschinen”, Jenseits von Mensch und Maschine, (Hrsg.: Susanne Beck), Baden-Baden, 2012, s. 125, 126; Kangal, s. 58, 59. 101 Anna Lohmann, Strafrecht im Zeitalter von Künstlicher Intelligenz, Robotik und Recht, Nomos, 2021, s. 112-113. 102Bu görüş için bkz.: Kangal, s. 59. 103 Taşdemir/Özbay/Kireçtepe, s. 815, 816. 104 Gerhard Seher, “Intelligente Agenten als ‘Personen im Strafrecht?” in- Gless, Sabine/Seelmann, Kurt (Hrsg.), Intelligente Agenten und das Recht, Baden-Baden, 2016, s. 50, 51. harekete göre daha dar kapsamlı olduğunu belirtmektedirler105. Bazı yazarlar, yapay zeka için iradi (özgür) hareketten bahsedebilmenin şu an için söz konusu olmadığını, suç faili olabilir denilecek seviyeye geldiğinde iradi hareket edip etmediklerinin tartışılacağını, yapay zekaya sahip varlıklar bir insan tarafından programlanarak çalıştırıldığından sınırlı bir irade özgürlüğüne sahip olduğunun söylenebileceğini belirtmektedirler106. Bazı yazarlar ise, güçlü bir yapay zeka teknolojisine sahip robot için en azından hareket yeteneği bakımından daha farklı düşünmenin söz konusu olabileceğini, eğer robotun yapay bir zeka ile otonom şekilde hareket etmesi veya işlem yapması söz konusu olacaksa bunun mümkün olabileceğini, aksi takdirde klasik robotik cerrahilerde kullanılan robot kollardaki gibi tamamen uzaktan kontrol ile hareket ettirilenlerin bir eşyadan farksız olduğunu, dolayısıyla da cezai sorumluluğu tartışmanın gereksiz olacağını ifade etmektedirler. İhmal açısından da aynı şeyin söylenebileceğini, yapay zekâ teknolojisine sahip bir robotun kendisinden beklenen sözleşmesel veya yasal bir yükümlülüğe aykırı şekilde, hareketi yapması halinde ihmalinin söz konusu olabileceğini ifade etmektedirler107. Öncelikle yapay zekanın bir insan olmadığı belirtilmelidir. İnsanı diğer canlılardan ayıran ve sorumlu olmasını sağlayan özelliği iradi davranabilmesidir. İrade, sözlük anlamıyla “bir şeyi yapıp yapmama konusunda kişinin kendi kendine karar verebilme ve bunu uygulama gücü” olarak tanımlanmaktadır108. İrade doktrinde, seçmek ve karar vermek ve bu seçimleri eyleme dönüştürmek; insanı, hareket ve davranışlarını kontrol eden bir güç olarak tanımlamaktadır109. Ceza hukukunda hareket, yönlendirici iradenin ürünü olarak nitelendirilmektedir. Zihinsel gücün devreye girmesi, iradi etkileşimin bulunması aranmaktadır. Tamamen fizyolojik olaylar, şuursuzluk halinde gerçekleştirilen davranışlar, refleks hareketleri fiil kapsamında kabul edilmemektedir. İnsan geniş aralıkta karar verebilmekte ve hareket edebilmektedir. Yapay zekanın kendiliğinden karar vermesi ve bu kararını gerçekleştirmesi, beşeri bir iradeyle hareket etmesi söz konusu 105 Çetin, s. 161, 162. 106 Enes Köken, “Yapay Zekânın Cezaı̇ Sorumluluğu”, TAAD, 12(47), 2021, s. 264. 107 Koray Doğan, Sürücüsüz Araçlar, s. 3237. 108 <https://sozluk.gov.tr>, Erişim Tarihi 02.08.2023. Yener Özen, “Değerler Felsefesi Açısından İrade ve Bileşenleri (Özgür Bir İrademiz Var Mı?)”, <https://dergipark.org.tr/tr/download/articlefile/149874#:~:text=Diğer%20 <BR>bir%20tanımda%20irade%2C%20bir,verme%20gücü%2C%20istenç%20olarak%20 <BR>tanımlanabilir>, Erişim Tarihi 2 Ağustos 2023, s. 2. değildir110. Ancak algoritma temelinde topladığı bilgilerden öğrenen, ihtimalleri hesaplayan, deneyimleyen, karar veren, sonuç çıkaran, uygun davranışı seçen ve uygulayan bir yapay zekanın bir hayvan veya araç konumunda olmadığı da bir gerçektir. Yapay zeka eğitilmiş modeller aracılığıyla çevresini algılayıp tanımlanan amaç doğrultusunda karar verebildiği gibi tanımlananın dışında da davranış da sergileyebilmektedir. Yapay zekalı sistemler, özel bir hedefe ulaşmaları istendiğinde sonuca ulaşma yollarına kendileri karar vermekte ve yollar arasında seçim yapabilmekte, hedefin farklı yollarını deneyebilmekte veya verilen görevi nasıl yerine getireceğini ve hedefin ne olduğunu öğrenebilmektedirler111. Hatasını farklı şekilde dizayn edilen yazılımdaki duruma göre anlayabilmekte ve düzeltebilmektedir. Yapay zeka, yazılımındaki duruma göre tepki verebilmekte, uygun davranışı seçip hareket edebilmektedir. Ancak bunu belli amaç veya görev doğrultusunda yapmaktadır. Bu anlamda hedeflenen hareketinin amaca yönelik olduğu söylenebilir. Ancak insan gibi genel ve geniş nitelikte bir iradeye ve kendiliğinden karar verme yeteneğine sahip olduğunu söylemek söz konusu değildir. Yapay zekanın kendi değerlendirmesine dayanan gerçek bir kararından bahsedilebilmesi, bu çerçevede kendisine hedefler koyduğunun ve eylemlerini bu hedeflere göre belirlediğinin söylenebilmesi şu an için mümkün değildir. Yapay zeka görevi mümkün olan en iyi şekilde yerine getirmesini sağlayan ara adımları bağımsız olarak belirleyebilmekle birlikte, seçimi gerçek kararlar niteliğinde olmayıp, aksine önceden tanımlanmış seçenekler arasında programlanmış bir seçim niteliğindedir112.İnsan gibi geniş aralıkta görev yürüten veya kararlar alabilen yapıya şuan için sahip değildirler. İnsan kontrolünden bağımsız, yazılımları ile sınırlı kalmayan, hedeflerini 110 “Genel anlamda bilinç, bir bireyin öznel ve biricik deneyimini (qualia), düşünceleri, duyguları ve hisleri deneyimlemenin nasıl bir şey olduğu yönünü ifade eder. İnsanlarda ve bazı hayvanlarda (en azından primatlarda ve ahtapotlarda), kişinin çevresinin, kendisinin ve zamanın geçişinin farkında olmasıdır”, Doğan Kökdemir, “Yapay Zeka Neredeyse Tamam: Peki Yapay Bilinç?, <https://www.birgun.net/makale/yapay-zeka-neredeysetamam-peki-yapay-bilinc-449790>, Erişim Tarihi 22 Temmuz 2023. 111 “Go oynayan bir program aynı zamanda borsa tahminleri yapamamaktadır. Dolayısıyla günümüzde derin öğrenme yöntemi ile belirli görevleri yerine getiren yapay zekâ uygulamaları dar anlamda bilişsel özgürlüğe sahiptirler diyebiliriz. Ancak tam bir bilişsel özgürlük için yapay genel zekâya ulaşılması zorunlu bir koşuldur. Yapay genel zekâ ise “insan benzeri beceri ile geniş aralıkta görevler yürütebilen yapay zekâ” anlamına gelmektedir (New Scientist, 2021, s. 291). Bu ise birçok bilim kurgu filminde karşımıza çıkan; Bill Gates, Stephen Hawking, Elon Musk gibi birçok düşünürün endişe ile yaklaştığı süper zekâların -insanüstü düzeyde bilişsel performansa sahip genel zekâya sahip sistemlerin- doğuşu anlamına gelmektedir (Bostrom, 2020, s. 39)”, Mehtap Doğan, Özgür İrade, s. 805 vd. 112 Gleß, Mein Auto fuhr zu schnell, s. 244. güncelleyebilen sistemler olduklarında ancak hareketlerinden bahsedilecektir113. Dolayısıyla yapay zekanın belirli bir amaca yönelik iradi olarak hareket edebildiklerini şu anki mevcut gelişmeler açısından kabul etmiyoruz. Ancak ileride yaşanacak gelişmeler yapay zekanın tamamen iradi olarak hareket etmesini sağlarsa hareket yeteneğinin bulunduğu söylenebilecektir. Ancak ceza hukukunda hareket yeteneğine sahip varlık yalızca gerçek kişi kabul edildiğinden her şeyden önce yapay zekanın hareket yeteneğinin olduğunun söylenebilmesi için gerçek kişi dışında belirleme yapılması gerekir. Bir başka ifadeyle hareketi sadece insan davranışı olarak ifade etmemiz gerekir. Ayrıca yapay zeka aracılığıyla bilişim ortamında işlenen suçlar düşünüldüğünde hareketi sadece dış dünyada cereyan eden insan davranışı olarak da nitelendirmemiz gerekir114. Teknolojik gelişmeler dikkate alındığında davranışın fiziki varlığı olanların hareketi olarak da değerlendirilmemesi gerekir. Dolayısıyla yapay zekanın robot olmasıyla bot olması hareket açısından önem taşımamalıdır. Yapay zekanın da dikkate alındığı bir hareket tanımlaması yapıldığında, iradi olarak belirli amaca yönelik olarak gerçekleştirilen, hükmolunan veya hükmolunabilir olan dış dünyada veya sanal alemde gerçekleştirilen davranışın hareket olduğu söylenebilecektir. Nitekim doktrinde bazı yazarlar tarafından, insan merkezci olmayan ceza hukuku kavramlarına dönüşten bahsedilmektedir115. Bazı yazarlar ise, şimdiye kadar kullanılan ceza hukuku kavramlarının insan olmayan varlıklara genişletilmesinin kavramsal olarak imkansız olmadığını belirtmektedirler116. Yapay zeka, sadece kendilerine yüklenen program çerçevesinde işlem yaptıklarında ise hareket yeteneklerinin bulunmadığı konusunda bir problem bulunmamaktadır. Burada yapay zekanın sadece araç olarak kullanılması söz konusudur. Yapay zekayı kullanan kişi doğrudan fail olacaktır. Programı yapan da şartlar gerçekleşmişse iştirak kuralları çerçevesinde sorumlu olacaktır. Ayrıca suç işlemek için yapay zeka üretildiğinde TCK m. 245/A’nın gerçekleşmesi 113 Mehtap Doğan, Özgür İrade, s. 791. 114 Hareket, irade tarafından hükmolunan veya hükmolunabilir olan, belli bir amaca yönelik olarak gerçekleştirilen ve dış dünyada cereyan eden insan davranışıdır: İzzet Özgenç, Türk Ceza Hukuku, Genel Hükümler, 18. Bası, Seçkin Yayıncılık, 2022, s. 179, 180; Mahmut Koca/İlhan Üzülmez, Türk Ceza Hukuku Genel Hükümler, 15. Baskı, Seçkin Yayıncılık, 2022, s. 101, 102. Türk hukukunda Demirbaş da gai hareket teorisini kabul etmektedir: Timur Demirbaş, Ceza Hukuku, Genel Hükümler, 17. Baskı, Seçkin Yayıncılık, 2022, s. 242. 115 Ziemann, s. 191 116 Hilgendorf, Können Roboter schuldhaft handeln, s. 125. söz konusu olacaktır. Yapay zekanın hareket yeteneği kabul edildiğinde ihmali hareketi de söz konusu olabilecektir. Belirli bir şekilde davranma hukuki yükümlülüğü yüklendiğinde ve bu yükümlülüğü yerine getirmediklerinde ihmali hareketleri söz konusu olacaktır. Davranışının amacını bilmek şartıyla ihmali hareketlerinin varlığı kabul edilebilecektir. Ancak burada yapay zekaya veya robota böyle bir yükümlülük yüklenebilecek mi sorusu gündeme gelmektedir. Yüklenebileceği söylenebilir. Sorun kusurlulukla ilgili olarak karşımıza çıkmaktadır. Ayrıca kusurdaki beklenebilirlik açısından da değerlendirme yapılması gerekmektedir. Zira bir insan için beklenemezlik kabul edilen bir durum robot için aynı şekilde değerlendirilemeyecektir. Zira bir insan için kendi yaşamı da tehlikeye gireceği için beklenemezlik söz konusu olurken, bir robot kolayca üretilebileceğinden, yeniden eski haline döndürülebileceğinden beklenebilirlik söylenebilecek veya tartışılabilecektir. Ancak yapay zeka konusunda ceza sorumluluğunun kabul edilmesi için ceza hukuku kabullerinin değişmesi veya yeniden yorumlanması gerekmektedir. Ceza hukukunu yapay zeka konusunda çözümlenmesi gereken zorlu sorular beklemektedir. Hareket yeteneği kabul edildiğinde yapay zekanın doğrudan failliği de söz konusu olabilecektir. Dolaylı faillik ve müşterek failliğin gerçekleşmesi de mümkün olacaktır. Doktrinde insanların ve yapay zekâlı robotların bir arada bulunduğu bir topluluk hayal edildiğinde, tüzel kişilerin ceza sorumluluğu, müşterek suç işleme (joint criminal enterprise) ve örgütsel hâkimiyete dayalı dolaylı faillik teorileri ve ürün sorumluluğu ile ilgili çeşitli tartışmaların gündeme geleceği ifade edilmektedir117. İştirak suçun maddi unsuru ve manevi unsuruyla ilgili özellik taşıdığı için suçun özel görünüş şekilleri olarak nitelendirilmektedir. İştirakte bir çok kişinin hareketi olmasına rağmen tek hareket kabul edilmekte, suça katılan herkesin hareketi icrahareketi olmadığı halde sorumluluk tayin edilmekte, müşterek faillik için fonksiyonel fiil hakimiyeti, şeriklik için çifte kast gerekmektedir. Dolayısıyla yapay zeka için hareket ve kast kabul edildiğinde iştirak söz konusu olacaktır. İştirak iradesi olmadan da bir insanla birlikte bir suçun gerçekleşmesine neden olabilir. Ayrı ayrı sorumluluk değerlendirmesi yapılacaktır. Yapay zekaların kendilerinin de birlikte suç işleme iradesiyle hareket etmesi veya diğerinin fiiline yardım etmesi de söz konusu olabilecektir. Ancak bugün için bunların söz konusu olmadığı belirtilmelidir. Tüzel kişi olarak kabul edilmeleri söz konusu olmamakla birlikte yapay zeka üreticilerinin sorumluluğu açısından sorun 117 Taşdemir/Özbay/Kireçtepe, s. 821, 822. değerlendirildiğinde günümüzdeki eğilimin tüzel kişilerin ceza sorumluluğu yönünde geliştiği görülmektedir118. Yapay zekayı üreten şirketlerin, tüzel kişilerin ceza hukuku sorumluluğu üzerinde gelişmeler yaşanacaktır. Dolaylı faillik açısından yapay zekanın dolaylı fail olması ile yapay zekanın suç işlemede kullanılması suretiyle dolaylı faillik söz konusu olabilir. Yapay zekayı kullanan veya programlayan kişinin dolaylı failliğinin söz konusu olacağı belirtilmelidir. Doktrinde yapay zekaya sahip varlıkların cezai sorumlulukları noktasında üç muhtemel sorumluluk modelinin söz konusu olacağı ileri sürülmektedir. Bunlardan ilkinin, dolaylı faillik sorumluluk modeli olduğu ifade edilmektedir. Bu halde yapay zekaya sahip varlığın herhangi bir insani nitelik taşıdığı kabul edilmemekte, ancak yapay zekaya sahip bir varlığın yeteneklerinin de görmezden gelinemeyeceği, bu yeteneklerin fail olmak açısından yetersiz olduğu (yapay zeka tam akıl hastası, çocuk gibi kusur 118 Doktrinde ekonomik suçlarla mücadele edebilmek ve hukuku etkin kılabilmek için tüzel kişilerin ceza sorumluluğunun kabul edilmesi yönünde eğilim bulunmaktadır: Nur Centel/ Hamide Zafer/Özlem Çakmut, Türk Ceza Hukukuna Giriş, 11. Baskı, Beta Basım Yayım Dağıtım, 2020, s. 253. Ayrıca bkz.: Walter Gropp, Strafrecht, Allgemeiner Teil, 3. Auflage, Springer, 2005, s. 144; Uğur Güner, “Ekonomik Suçlar ve Ekonomi Ceza Hukukuna İlişkin Yasal Düzenlemeler”, D.E.Ü. Hukuk Fakültesi Dergisi, Prof. Dr. Durmuş TEZCAN’a Armağan,21(Özel S.) 2019,s. 1431; Koray Doğan, “Tüzel Kişilerin İdari Para Cezası Sorumluluğunda İsnadiyet Sorunu”, D.E.Ü. Hukuk Fakültesi Dergisi, 17(1), 2015, s. 23. Bazı uluslararası çalışmalarda da tüzel kişinin fail olması yönünde belirlemeler bulunmaktadır. Bkz.: Selman Dursun, “Türk Ceza Hukuku Reformunun Ekonomi Ceza Hukukuna Etkileri”, <http:// <BR>www.selmandursun.com/wp-content/uploads/sdursun-tch-reformu-ekonomi-ceza.pdf>, Erişim Tarihi 25 Ağustos 2023,s. 2245, 2246, dipnot 19. Örneğin, İsviçre, İspanya, Kanada, Finlandiya, ABD, Avusturalya, Hırvatistan, Danimarka, İngiltere ve Fransa hukuk sistemlerinin tüzel kişilerin fail olmasını kabul etmiştir: Koray Doğan, Tüzel Kişiler, s. 23. Uluslararası hukukta ise bu eğilimin nedeni olarak Avrupa Birliği Müzakereleri sürecinde müzakerelerin başlaması için konulan kıstaslar (mevzuatın uyumlaştırılması), OECD bünyesinde çalışmalarını yürüten Mali Eylem Görev Gücü (FATF) ve Yabancı Kamu Görevlilerine Rüşvet VerilmesininÖnlenmesi Çalışma Grubunun Tavsiye Kararları ve Avrupa Konseyi bünyesindeki Yolsuzluğa Karşı Devletler Grubu (GRECO) tavsiye kararları olduğu belirtilmektedir: Güner, s. 1431; Dursun, Ekonomi Ceza Hukuku, s. 2246, dipnot 19. Avrupa Birliği hukukunda suçlarda tüzel kişinin sorumluluğunun kabul edilmesine ve idari yaptırımlardan cezai yaptırımlara doğru artan eğilim bulunmaktadır (“6AMLD (AMLD5 (Anti Money Laundering Directive-3 Aralık 2020’de yayımlanan ve uygulama tarihi 3 Haziran 2021 olarak kabul edilen 2018/1673 sayılı AMLD6’yı yayımlamıştır), kara para aklamayla bağlantılı cezai davranışın kapsamını genişletmiş ve cezai sorumluluk açısından tüzel kişilerin de sorumluluğunu kabul etmiştir. Dolayısıyla kuruluşların kendileri için çalışan kişiler tarafından işlenen suçlardan dolayı cezalandırılabileceği anlamına gelmektedir, <file:///Users/berrinakbulut/Desktop/6.%20Kara%20Para%20Aklamayı%20Önleme%20Direktifi%20(6AMLD):%20Bilmeniz%20 Gerekenler.html>, Erişim Tarihi 25 Ağustos 2023. Buna gerekçe olarak, etkileri itibariyle cezai yaptırımın daha ağır ve caydırıcı olması, yargılama sonucunda verilmesi nedeniyle usulü güvenceleri içermesi ve hata oranının düşük olması gösterilmektedir: Merve İnan Orman, “Avrupa Birliği Hukukunda İdari Para Cezaları”, Kabahatler Hukuku Yazıları-II, 2018, s. 141. yeteneği ortadan kalkmış insanlara benzetilmektedir) belirtilerek yapay zekayı kullanan veya programlayan kişinin dolaylı fail olarak sorumlu olacağı ifade edilmektedir. Ancak bu sorumluluk şeklinde, yapay zekanın suç işlemek için programlanmamakla beraber yine de yapay zeka tarafından suçun gerçekleştirilmesi hali için elverişli olmadığı ileri sürülmektedir119. Dolaylı failliğin söz konusu olması için ceza hukukunda araç kişinin fiili üzerinde arkadaki kişinin (dolaylı failin) irade hakimiyeti kurması gerekmektedir. İrade hakimiyetinin söz konusu olduğu hallerde dolaylı faillik gerçekleşecektir. Yapay zeka bir insanın konuşmasıyla da yönlendirilebilmektedir. Yapay zekanın amacı, örneğin hataya düşürülmek suretiyle değiştirildiğinde dolaylı faillik söz konusu olabilecektir. Ancak yapay zeka sahip varlıklar veya yapay zeka kısmen otonom olarak hareket ettiğinde, amacını isteyerek değiştirdiğinde fiil üzerinde hakimiyet kurulamayacaktır. Doktrinde burada irade hakimiyeti değil program hakimiyeti kavramının kullanılması önerilmektedir120. Doktrinde de yapay zekânın kaybettiği/sahip olduğu otonominin derecesine göre yazılımını kıranın doğrudan veya dolaylı fail olarak sorumlu tutmanın düşünülebileceği ifade edilmektedir121.Organizasyon hakimiyeti çerçevesinde yapay zekanın kullanılması da söz konusu olabilecektir. Yapay zekanın tamamen araç konumunda bulunduğu veya tamamen kendi iradesiyle hareket ettiği veya organizasyon hakimiyetinin bulunmadığı durumlarda ise dolaylı faillik gerçekleşmeyecektir. Somut olayda programı yapan veya kullanan ile yapay zekanın ne şekilde hareket ettiğinin değerlendirilmesi gerekmektedir. Yapay zekanın kendisi de dolaylı fail olabilir. Bir insanı veya bir başka yapay zekayı suç işlemede kullanabilmesi teknolojik gelişmeler çerçevesinde ihtimal dahilinde bulunmaktadır. Bu durumda da yapay zekanın dolaylı fail olması için hareket yeteneğinin bulunduğunun kabul edilmesi gerekir. Yapay zekaya sahip varlıkların cezai sorumlulukları noktasında hareket yeteneklerinin ve suç işleyebileceklerinin kabul edildiği durumlarda, kullanıcı veya programı yapan kişinin sorumlu olması da söz konusu olabilecektir. Yapay zekanın işlediği suç, kullanıcı veya programı yapan kişinin hareketinin olası doğal sonuçları olduğunda sorumluluk kabul edilmektedir. Bu sorumluluk şeklinde yapay zekaya sahip varlık suç işlemekte, ancak programcı veya 119 Model hakkında bkz.: Gabriel Hallevy, “Yapay Zekaya Sahı̇p Varlıkların Cezaı̇Sorumluluğu -Bı̇lı̇m Kurgudan Yasal Toplumsal Denetı̇me”, (Çev.: Müslim Fincan), Küresel Bakış, (24), 2018, s. 117 vd. 120 Kangal, s. 93. 121 Bkz.Taşdemir/Özbay/Kireçtepe, s. 815, 816. kullanıcı suçun işlenmesi için plan yapmamakta ve suça iştirak etmemekte, hatta suçun işlenmesiyle ilgili bilgiye de sahibi bulunmamaktadırlar. Bu durumda kişi, işlenen suç kendi davranışının olası, doğal sonucu olduğu için, makul bir insanın bilmesi gerektiği kabul edilen kişi olarak nitelendirilmektedir. Programı yapan ya da kullanıcıların, suçun işlenebileceğini öngörmeleri ve yapay zeka tarafından işlenmesine engel olmaları gerektiği kabul edilmektedir. Örneğin yapay zeka uçuş görevinin bir parçası olarak uçağı korumaya programlanmıştır. Uçuş esnasında insan ola pilot, otomatik pilotu (yapay zekaya sahip varlık olan) etkinleştirir, ancak daha sonra pilot, yaklaşan bir fırtınayı görür ve görevi iptal etmeye ve askeri üsse geri dönmeye çalışırsa da yapay zeka, pilotun eylemini görev için bir tehdit olarak algılayarak bu tehdidi bertaraf etmek için harekete geçer ve pilotu öldürür. Daha önce belirtilen simülasyon örneğindeki bir olayın gerçek hayatta yaşandığı düşünüldüğünde de aynı durum söz konusudur. Bu gibi olaylarda programcının sorumluluğu kabul edilmektedir. Zira hiç bir kısıtlama olmaksızın yapay zekanın görevini yerine getirecek şekilde programlaması nedeniyle programcının pilotun öldürülmesinden sorumlu olacağı belirtilmektedir122. Yapay zekanın suç işleyeceğinin öğrenilmesine rağmen müdahale edilmemesinde ihmali şekilde kasten işlenen suç söz konusu olacaktır. Zira bu andan itibaren garantörlük bulunmaktadır. Garantörlüğü bulunmayan kişilerin yapay zekanın işlediği fiil nedeniyle zarar gören kişiler açısından TCK m. 98 söz konusu olacaktır. Yapay zekaya sahip varlığın plandan sapması ve planlanan suçun yerine ya da buna ek olarak bir başka suçu işlemesi durumunda da programı yapan veya kullanıcının sorumlu tutulması söz konusu olabilecektir. Meydana gelen bir olayda twitter üzerinden gönderilen twitlerin analizini yapan yapay zekâ algoritması Tay, ırkçı bir söylemi öğrenmiş ve açmış olduğu bir hesap üzerinden bazı kişilere yönelik ırkçı söylemlerde bulunmuştur123. Öğrenilmesine rağmen fiile engel olunmaması durumunda üretici veya programcı ihmalinden dolayı sorumlu olacaktır. Özen kurallarına aykırılığın söz konusu olduğu olaylarda da fiilin taksirli şekli olmak şartıyla taksirden dolayı sorumluluk söz konusu olacaktır. Ancak bu gibi olaylarda objektif isnadiyet kriterlerinin de değerlendirilmesi gerekir. Örneğin yaratılan risk izin verilen risk sınırları içindeyse sorumluluk söz konusu olmayacaktır. Bu anlamda yapay zekalı uygulamaların veya araçların üretilmesi, kullanılması konularında yasal düzenlemelerin 122 Bkz.: Hallevy, s. 122 vd. 123 Olgun Değirmenci, “Yapay Zekâ ve Ceza Hukuku Sorumluluğu”, <https://www.academia. <BR>edu/42794137/Yapay_Zeka_ve_Ceza_Sorumluluğu>, Erişim Tarihi 25 Temmuz 2023, s. 13.Ayrıca bkz.: Hallevy, s. 125. yapılması, izin verilen risk alanlarının belirtilmesi gerekmektedir. Yapay zeka kullanımı artık bir risk oluşturmakta ve gittikçe daha fazla risk oluşturmaya da devam edecektir. İnsan hayatına kattığı yararlardan dolayı kullanımından ve gelişmesinden vazgeçemeyeceğimize göre, kuralların oluşturulması gerekmektedir124. Yapay zeka kullanımı açısından izin verilen risk alanlarının ve özen kurallarının oluşturulması önem taşımaktadır. Otonom araçlar125 ile ilgili çalışmalar olmaktaysa da126sadece bu alanda değil, program çerçevesinde hareket edenler dışındaki yapay zekalar açısından sınırların çizilmesi, kuralların ortaya konulması gerekmektedir. Özen kurallarına aykırılık, suç için programlama veya kullanma söz konusu olmamasına rağmen, yapay zekanın kedisinin suç işlemesinde ise kullanıcı veya programcının sorumluluğu bulunmayacaktır127. Yapay zekanın gerçekleştirdiği fiil kullanıcı veya programcının hükmedebilirlik alanı dışındaysa sorumlulukları bulunmayacaktır. Yine başka birinin sorumluluk alanında gerçekleşen neticelerde kullanıcı veya programı yapana sorumluluk isnad edilemeyecektir. Sorumluluğun belirlenmesinde objektif isnadiyet kriterlerinin göz önüne alınması gerekmektedir128. Üreticinin veya programcının sorumlu olmasıyla yapay zekanın sorumluluğu ayrı değerlendirilmelidir. Yapay zekanın doğrudan neden olduğu zararlarda üreticinin veya programcının sorumlu olması da 124 Otonom araçların izin verilen risk mi oluşturduğu konusunda bkz.: Gless, s. 240 vd. 125 Otonom araçlar, kısmen ya da tamamen yapay zeka sistemi kontrolüne sahiptirler. Bu araçlar sadece karayolunda değil hava yolu, deniz yolu ve raylı sistem taşımacılığında da kullanılabilmektedir. 126 Otonom araçlara ilişkin ilk hukuki metin olan “Kaliforniya Taşıt Kanununda” otonom teknoloji, bir taşıtı bir insan operatörünün aktif fiziksel kontrol ya da gözetimi olmaksızın sürme kapasitesine sahip teknoloji olarak tanımlanmıştır. Otonom teknoloji donanımına sahip, bu teknolojiye entegre edilen araçlara ise otonom araç adı verilmektedir (Koray Doğan, Sürücüsüz Araçlar, s. 3230). ABD’nin birçok eyaletinde otonom araçlara ilişkin düzenleme yapılmıştır. İngiltere’de otonom araçların test sürüşüne 2015 yılında izin verilmiş (Code of Practice), 2019’da bu düzenlemede değişiklik yapılmıştır. İngiltere’de otonom araçlara özgü düzenlemeler içeren Otomatik ve Elektrikli Araçlar Yasası-2018 bulunmaktadır. Almanya’da Karayolları Trafik Kanununda 2017 yılında değişiklik yaparak otonom araçlarla ilgili mevzuatını ulasal çapta güncelleyen ilk ülke olmuştur. Fransa’da otonom araçlara ilişkin test sürüşleri Kararname (2016) aracılığı ile düzenlenmiştir. Avusturya 2016’da Motorlu Araçlar Trafik Kanununda değişikliğe gitmiş (Şahin, s. 988 vd.), Singapur 2017 yılında otonom araçların karayollarında alışmasını düzenleyen kanun çıkarmış, Güney Kore 2019’da mevzuatında değişikliğe gitmiş, 2020 yılında Otonom araçların Ticarileştirilmesinin Teşvik edilmesi ve Desteklenmesi Hakkında Kanunu kabul etmiştir. 127 Değirmenci, s. 13. 128 Objektif isnadiyet kriterleri içinbkz. Berrin Akbulut, Türk Ceza Hukuku, Genel Hükümler, 9. Baskı, Adalet Yayınevi, 2022, s. 384 vd. söz konusu olabilecektir129. Alman hukukunda da sorumluluğun bulunduğu kabul edilmekte, ancak sorumluluğun belirlenmesinin sorun teşkil ettiği ifade edilmektedir130. Yapay zekanın kast veya taksirinin bulunup bulunmadığı da tartışma doğuran hususlardandır. Yapay zekalı araçların kasten işlenen suçlarda araç olarak kabul edilmesi gerektiği, ancak taksirli suç işleyebilecekleri bazı yazarlar tarafından belirtilmektedir. Her ne kadar öğrenme ve karar vermeleri söz konusu olsa da belirli amaca yönelik olarak hareket edemeyecekleri ifade edilmelidir131. Belirli amaca yönelik olarak hareket ettiklerinin kabul edilmesi halinde ise kastlarının da söz konusu olabileceğini düşünüyoruz. Ancak bunun için öncelikle hareket yeteneklerinin bulunduğunun kabul edilmesi gerekir. Taksir açısından soruna yaklaşıldığında, yapay zekanın belirlenen hedef açısından bir insana göre öngörülebilirliklerinin çok daha fazla olduğu, bütün ihtimalleri hesaplayabildiklerini göz önünde tutmak gerekir. Ancak somut olayda hesaplayamadığı, fark edemeyeceği durumlar da söz konusu olabilir. Örneğin yapay zekalı bir araçışık levhasının bulunduğu yerde, bir kişiyi trafik polisi sanarak o kişiye göre davranmış veya yandaki araç hareket ettiğinde, aracın hareket etmesi yeşil ışıkla orantılı olduğu için yeşil ışık yandığını hesaplayarak hareket etmiş olabilir. Hatasını ise farklı şekilde dizayn edilen yazılımdaki duruma göre anlayabilmekte ve düzeltebilmektedir. Ya da programın yeniden düzenlenmesi ile ortadan kaldırılabilmektedir. Dolayısıyla tanımlanan amacın dışında hareket ettiğinde, yapay zekanın hatasından bahsedilebilmektedir. Dolayısıyla ceza hukukunda taksir bağlamında yapay zekanın hatasından bahsedilecek mi ve cezalandırılabilecek midir? Yapay zekanın ceza sorumluluğu kabul edildiği takdirde öngörmelerinin mümkün olup olmadığının değerlendirilmesi gerekmektedir. Belirtilen durumda özen yükümlülüğünün ihlalinden değil, programdaki hatadan bahsedilecektir. Doktrinde bazı yazarlar tarafından yapay zeka ve robotlar için kast ve taksir kavramları yerine amaçlama/hedefleme ve işlem hatasının yol açtığı sorumluluk şeklinde iki kavramın kullanması önerilmektedir. Robotun insanın beş duyu organını taklit eden sensörler, radarlar, kameralar ve mikrofonlar aracılığıyla bilme konusunda insandan daha üst seviyelere çıkabileceği kabul edilmekte, ancak sadece veri toplamanın bilerek hareket etme açısından yeterli olmadığı benimsenmektedir. İnsanın çevreden topladığı veriyi beyninde seri şekilde 129 Hallevy, s. 126 vd. 130 Gless, Mein Auto fuhr zu schnell, s. 246. 131 Bkz. Aksoy, s. 22. zihinsel faaliyetten geçirerek, analiz ederek bilgi olarak işlediği, bunu yapay zekanın da sergileyebileceği, dolayısıyla kastın bilme unsuru bakımından insan ile robotun benzer durumda olduğu, isteme unsuru yerine amaçlama/hedefleme unsuru teriminin daha uygun olduğu belirtilmektedir. Taksirin alternatifi olarak ileri sürülen arıza veya işlem hatası sonucu neticeye neden olma bakımından taksirin insanlar için geçerli unsurlarından farklı düşünmek gerektiği, objektif özen yükümlülüğünün ihlalini aramanın yersiz olduğu, robotun programlanış şekli itibariyle mevcut normlara uygun hareket etmesinin beklendiğini, robotta teknik bir arıza veya işlem hatasının aranması gerektiği, öngörme bakımından insanlardan daha iyi öngörebildiklerini, arızadan kaynaklı olarak neden olunan neticeden robotun cezalandırılması yerine yeniden programlanması veya var olan programın güncellenmesinin beklenebileceğini ileri sürmektedirler132. Yapay zekanın ceza sorumluluğu kabul edildiğinde, işlediği fiillerde netice sebebiyle ağırlaşan suçların gerçekleşmesi de söz konusu olabilecektir. Yapay zeka programcısının, kullanıcısının yapay zekanın gerçekleştirdiği fiille ilgili kastı veya taksirinin bulunacağını da bir kez daha ifade etmek isteriz. Yapay zekanın davranışlarının öngörülüp öngörülemeyeceği üzerinde de durulmaktadır. Yapay zekaya hukuka uygun davranacaklarına güvenilmemesi, denetim görevinin yerine getirilmesi gerektiği, aksi halde görevini yerine getirmeyen kişinin sorumluluğunun söz konusu olacağı belirtilmektedir133.Ancak sürekli yapay zekanın veya aracın gözetlenmesinin ve düzeltmesin özen yükümlülüğü olarak yüklenmesinin gayri meşru olacağı belirtilmektedir. Sistemin düzgün çalıştığından şüphe etmesini gerektirecek bir neden yoksa herhangi bir uyarı durumunda veya tehlikehalinde müdahale etmesi gerektiği ileri sürülmektedir134. Ayrıca makinelerin diğer makinelerin davranışına güvenip güvenemeyeceği konusunda da belirleme yapılmaktadır. Doktrinde makinelerin insan kaynaklı hatalı davranışları dikkate alacak, diğer makinelerin kurallara uygun hareket edeceği yönünde, yani diğer makinelerin kurallara uygun davrandığına güvenilebileceği şeklinde kurgulanmasının savunulabileceği ifade edilmektedir135. Yapay zekayla ilgili tartışılacak diğer bir konu hukuka uygunluk 132 Bkz. Koray Doğan, Sürücüsüz Araçlar, s. 3238 vd. 133 Ayrıntılı bilgi için bkz. Joerden, s. 207-209 134 Gless, s. 235, 236. 135 Eric Hilgendorf, “Otomatikleşmiş Sürüş ve Hukuku-Genel Bir Bakış”, (Çev.: Barış Atladı), Ceza Hukukunda Robot, Yapay Zeka ve Yeni Teknolojiler, Karşılaştırmalı Güncel Ceza Hukuku Serisi 21 (Ed. Yener Ünver), 2021, s. 454. nedenlerinin uygulanıp uygulanamayacağı136 ve yapay zekaya karşı saldırı gerçekleştirildiğinde korunması gereken hukuki değerinin kabul edilip edilmeyeceğidir137. Kişilik tanınıp hak sahibi kabul edildiklerinde, görev ve yetkileri söz konusu olduğunda hukuka uygunluk nedenlerinden yaralanabilecekler ve hukuki değerlerinin korunması söz konusu olabilecektir. Örneğin meşru savunma, kanun hükmünün yerine getirilmesi (örneğin kolluk olarak görev yapması), hakkın kullanılması ve ilgilinin rızası (örneğin tıbbi müdahale) hukuka uygunluk nedeni uygulanabilecektir. Yapay zekaya kötü muamele yapıldığında, hakaret edildiğinde veya bir başka suç işlendiğinde korunması yoluna gidilebilecektir. Robotların faaliyetine son verecek hareketlerin yapılması durumunda öldürme suçunun kabul edilip edilmeyeceği de sorun olarak ortaya çıkmaktadır. Zira insanın geri getirilmesi söz konusu değilse de robotun veya yapay zekanın tamir edilmesi, tekrar faaliyet yapması mümkün olabilmektedir. Yapay zeka saldırı yaptığında zorunluluk hali uygulanacaktır (ceza hukukunda insandan kaynaklanan davranış arandığından şu an için bu kabul edilmediğinden meşru savunma uygulanamayacaktır). Yapay zeka kapsamında yükümlülüklerin çatışması hukuka uygunluk nedeni kapsamında ifade edilen ve zorunluluk hali mi yükümlülüklerin çatışması mı olduğu konusunda tartışmalı olayların gerçekleşmesi de mümkündür. Örneğin yolda kaza yapmış bir araç ve iki kişi bulunmaktadır. Bu kişilerden biri yolda yatmaktayken diğeri yol kenarına gidebilmiştir. Yoldan gitmekte olan otonom araç manevra yapmadığında yoldaki kişiye çarpacak, manevra yaptığında ise yol kenarındaki şahsa çarpacaktır. Bu gibi olaylarda otonom aracın nasıl programlanması gerektiğinin sorun oluşturduğu belirtilmektedir. Her iki kişinin yaşamı aynı derecede olduğu için aracın manevra yapmamak üzere programlanması gerektiği belirtilmektedir. Yine yolda iki kişinin yattığı, yol kenarında ise bir kişinin yattığı olayda sorunun çözümü daha zor olsa da ağırlıklı görüşün yapay zekanın manevra yapmaması şeklinde programlanması olduğu ifade edilmektedir. Yolda üç çocuğun bulunması, birinin önde diğerlerinin 136 Uygulamadaysa üç robot yasasındansöz edilmektedir. “Üç robot yasası, Amerikalı bilimkurgu yazarı Isaac Asimov tarafından ortaya atılan, robotların işlev ve haklarına ilişkin yasalar-dır. Asimov’un ilk kez 1942 yılında yayımlanan, daha sonrasında Ben Robot isimli kitabının da bir bölümünü oluşturan “Durağan Döngü” isimli hikâyesinde ortaya attığı üç yasa şu şekildedir: -Bir robot, bir insana zarar veremez ya da zarar görmesine seyirci kalamaz. -Bir robot, birinci kuralla çelişmediği sürece bir insanın emirlerine uymak zorundadır. -Bir robot, birinci ve ikinci kuralla çelişmediği sürece kendi varlığını korumak zorundadır”, <https://tr.wikipedia.org/wiki/Üç_robot_yasası>, Erişim Tarihi 22 Temmuz 2023. 137Taşdemir/Özbay/Kireçtepe, s. 823, 824. hemen gerisinde olduğu, yapay zekanın yola devam etmesi halinde bir çocuğun sol çamurluk bölgesinden diğer iki çocuğun ise sağ çamurluk bölgesinden darbe alacağı ve aracın kaçma manevrası yapmasının söz konusu olmadığı olayda bütün yaşamları aynı değerde gören anlayış açısından sağa, sola veya düz gitmesinin herhangi bir farkının olmadığı belirtilmektedir. Ancak çoğu insanın ahlaki açıdan sadece bir çocuğun darbeye maruz kalmasının tercih edeceği ileri sürülmektedir138. C. KusurAçısından Diğer bir tartışılan ve kanaatimizce en önemli husus ise yapay zekanın kusur değerlendirmesine konu olup olamayacağıdır. Ceza hukukunda kusurun varlığı için kusur yeteneğinin bulunması, kusurluluğu kaldıran nedenlerin bulunmaması ve haksızlık bilincinin bulunması gerekmektedir. Kusur yeteneğinin bulunması kişide algılama ve irade yeteneğinin bulunmasını ifade etmektedir. Doğruların ancak sezgiyle bilineceği ve ilk ilkelerin sezgi yoluyla kavranıp başka yargılara tümden gelim yoluyla varılacağı belirtilmektedir. Sezginin akıl yürütmenin önemli evresini oluşturduğu ifade edilmektedir139. Sezgi doğrudan doğruya kavramadır. Sezginin daha çok geçmiş bilgiye dayalı olduğu, deneyim ve uzmanlığın artmasıyla doğru orantılı olarak geliştiği kabul edilmektedir140. İnsanlar yapay zekayla kıyaslandığında içgüdüsel duygulara, reflekslere ve dürtüsel tepkilere sahiptir. Yapay zekada bunların olmaması nedeniyle sezgi yetisinin yapay zekâya aktarılmasına yönelik çalışmalar yapılmakta, yürütülen proje kapsamında, tıpkı bir bebek gibi, sezgisel fiziği, yani evrenimizdeki mekaniğin nasıl çalıştığına dair sağduyu anlayışını öğrenebilen bir yapay zeka sistemi tasarlanmıştır. PLATO141adı verilen yapay zeka projesi sonucunda, 28 saatlik eğitimin ardından PLATO’nun öğrenebildiği anlaşılmış, zaman içerisinde PLATO’nun gözlem, kavrayış ve öngörülerinin gittikçe daha iyi hale geldiği 138 Hilgendorf, Otomatikleşmiş Sürüş, s. 448 vd. 139 Okuyucu Ergün, s. 733. 140 Okuyucu Ergün, s. 733, 734. 141 ‘Physics Learning Through Auto-encoding and Tracking Objects’in (Otomatik Kodlama ve Nesneleri İzleme Yoluyla Fizik Öğrenimi) baş harflerinin bir araya getirilmesiyle oluşturulmuştur görülmüştür142. Sezgi, bilinçvasıtasıyla ortaya çıkmaktadır143. Bilinç, insanın kendisini ve çevresini tanıma yeteneğini ifade etmektedir144.Bir kişinin bir şey hakkındaki farkındalığı veya algısı olarak tanımlanmaktadır145. Farkındalığı fark etme halidir146. Yapay zeka için, yapay bilinç kavramı kullanılmaktadır. Yapay bilinç mümkün müdür sorusuna net cevap verilememektedir. Yapay zekalı sistemlerde öznel bilincin rastgele ya da bizim bilmediğimiz bir şekilde ortaya çıkması için bir engel de olmadığı, yapay bilincin, yalnızca bilişsel ve sosyal olmak üzere iki yönünden bahsedilebileceği, bu da yapay bilincin insan bilincinden farklı yeni bir bilinç türüne işaret ettiği, bu bilinç türünün bilişsel kapasitesi insan bilinciyle eşdeğer ya da onu aşmış olacağı ancak ilkece öznel bilinç sahibi olan kendinin bilincinde metafizik bir özne olamayacağı ileri sürülmektedir147. Dolayısıyla bugün için yapay zeka bir bilince sahip değildir. Algılama, bilinç hallerinden biridir. Bilinç varsa algılama yeteneğinden bahsedebiliriz. Algılama, duyu organlarımıza gelen uyaranları değerlendirme, yorumlama ve doğru-yanlış diye anlamlandırma sürecini ifade etmektedir148. Algılama yeteneği, insanın çevresindeki nesnelerin ve olayların 142<https://www.posta.com.tr/bilim-teknoloji/sezgileri-ogrenebilen-yapay-zeka-bebegi<BR>gelistirildi-2539758>, Erişim Tarihi 23 Temmuz 2023. 143Bilinç ve sezgi ilişkisi için bkz. Ayşe Eroğlu, “Henri Bergson’da Bilinç-Sezgi İlişkisi”, SDÜ Fen Edebiyat Fakültesi Sosyal Bilimler Dergisi, (27), 2012, s. 81-102, s. 81 vd. 144 <https://sozluk.gov.tr/> 145 Kemal Arıkan, “Bilinç ve Bilinçli Olmak Nedir?”, <https://www.kemalarikan.com/ <BR>bilinc-ve-bilincli-olmak-nedir.html#:~:text=%C4%B0ngilizcenin%20klasik%20 <BR>s%C3%B6zl%C3%BCklerinden%20olan%20Oxford,ger%C3%A7ekle%C5%9Ftirme%20 <BR>halinin%20kendisine%20bilin%C3%A7%20denmektedir>, Erişim Tarihi 23 Temmuz 2023. 146 Özen, s. 5. 147 Bilincin zor problemi alışılagelmiş bilimsel yöntemlerle açıklanmaya direnç gösteren “deneyim” problemi olduğu belirtilmektedir. Bunun için de öznelliğin, fiziksel dünyada ne şekilde ortaya çıktığını açıklayabilmek, deneyimlerimizin varlığını nasıl bu kadar gerçek ve derinden hissettiğimizi çözümleyebiliyor olmak gerektiği ileri sürülmektedir. Fakat her iki seçeneğin de şimdiye kadar, onlarca farklı bakış açısından denenmiş olmasına rağmen ikna edici bir perspektife ulaşılamadığı belirtilmektedir. Bilincin zor problemi alışılagelmiş bilimsel yöntemlerle açıklanmaya direnç gösteren “deneyim” problemi olduğu belirtilmektedir. Bunun için de öznelliğin, fiziksel dünyada ne şekilde ortaya çıktığını açıklayabilmek, deneyimlerimizin varlığını nasıl bu kadar gerçek ve derinden hissettiğimizi çözümleyebiliyor olmak gerektiği ileri sürülmektedir. Fakat her iki seçeneğin de şimdiye kadar, onlarca farklı bakış açısından denenmiş olmasına rağmen ikna edici bir perspektife ulaşılamadığı belirtilmektedir. Tasvir edilen yalnızca bilişsel, davranışsal ve sosyal olarak insana benzeyen sistemlerin, felsefi zombilerden farkları ise rastlantısal olarak deneyimlere sahip olma olasılıkları olacağı ifade edilmektedir: Mehtap Doğan, “Yapay Zeka ve Bilinç”, https://turkiye.ai/yapay-zeka-ve-bilinc/, Erişim Tarihi 23 Temmuz 2023. 148Erol Özmen, “Algı/Algılama”, https://psikoloji-psikiyatri.com/algi-algilama/, Erişim Tarihi bilincinde, idrakinde olma yeteneğini ifade etmektedir149. İnsanın etrafındaki olguları gözlemleyebilme ve bunlardan belli sonuçlar çıkarabilmesidir150. Ceza hukukunda ise, fiilinin hukuki anlam ve sonucunu anlayabilecek durumda olmayı ifade etmektedir. Yapay zeka bugün için bu yetiye sahip olmayıp, kendi hareketlerini iyi veya kötü olarak değerlendirememektedir151. Dolayısıyla da fiilinin hukuki anlam ve sonuçlarını algılayabilecek düzeyde de değildir. Algılama yeteneği olmadığı gibi irade yeteneklerinin bulunduğunun söylenmesi de söz konusu değildir. Doğruyu yanlışı ayırt edip, doğruyu yapma imkanına sahipken yanlışı yerine getirmeye karar verme yetisi bulunmamaktadır. İrade özgürlüğü, bağımsız seçim yapma ve karar verme yetisi olarak ifade edilebilir. Bağımsız karar verebilmek için, bağımsız motivasyonlara ya da belirlenmemiş hedeflere sahip olmak gerekmektedir. Hedefleri baştan belirlenmiş hiçbir yapının özgür iradesinin bulunmadığı belirtilmelidir. Ayrıca özgür iradenin varlığı için, belirli olmayan hedefler geliştirme yetisi yanında belirli olmayan motivasyonlara da sahip olunması gerekmektedir. Yapay zekalı sistemler, özel bir hedefe ulaşmaları istendiğinde sonuca ulaşma yollarına kendileri karar vermekte ve yollar arasında seçim yapabilmekte, hedefin farklı yollarını deneyebilmekte veya verilen görevi nasıl yerine getireceğini ve hedefin ne olduğunu öğrenebilmektedirler. Ancak sonuçta belli bir veya birkaç amaç, görev doğrultusunda eylemde bulunabilmektedirler. İnsan gibi geniş aralıkta görev yürüten veya kararlar alabilen yapıya şuan için sahip değildirler. İnsan kontrolünden bağımsız, yazılımları ile sınırlı kalmayan, hedeflerini güncelleyebilen sistemler olduklarında özgür hareketten bahsedilecektir152. 23 Temmuz 2023. 149<http://tdk.gov.tr/index.php?option=com_bts&arama=kelime&guid=TDK. <BR>GTS.56db62378b03c3. 49766919>, Erişim Tarihi 23 Temmuz 2023. 150 Özgenç, s. 458. 151 Gless/Silverman/Weigends, s. 129. 152 “Go oynayan bir program aynı zamanda borsa tahminleri yapamamaktadır. Dolayısıyla günümüzde derin öğrenme yöntemi ile belirli görevleri yerine getiren yapay zekâ uygulamaları dar anlamda bilişsel özgürlüğe sahiptirler diyebiliriz. Ancak tam bir bilişsel özgürlük için yapay genel zekâya ulaşılması zorunlu bir koşuldur. Yapay genel zekâ ise “insan benzeri beceri ile geniş aralıkta görevler yürütebilen yapay zekâ” anlamına gelmektedir (New Scientist, 2021, s. 291). Bu ise birçok bilim kurgu filminde karşımıza çıkan; Bill Gates, Stephen Hawking, Elon Musk gibi birçok düşünürün endişe ile yaklaştığı süper zekâların -insanüstü düzeyde bilişsel performansa sahip genel zekâya sahip sistemlerin- doğuşu anlamına gelmektedir (Bostrom, 2020, s. 39)”, Mehtap Doğan, Özgür İrade, s. 805 vd. Yapay zeka, bugün için fiilininhukuki alam ve içeriğini anlama yeteneğine sahip olmadığı için haksızlık bilincine de doğal olarak sahip değildirler. Kusurluluğu ortadan kaldıran nedenlerin uygulaması da bugün için söz konusu değildir. Belirtilen nedenlerle yapay zekanın kusur değerlendirmesine konu olmaları bugün mümkün gözükmemektedir. Ancak insan kontrolünden bağımsız, yazılımı ile sınırlı kalmayan, hedefini güncelleyebilen sistem olduğunda, hareketinin hukuken kabul edilemez olduğunu ve bu nedenle de hareketinin “negatif” olarak değerlendirmesi gerektiğini fark ettiğinde kendi hareketlerinden sorumlu tutulabilmeleri söz konusu olacaktır153.Bu çerçevede kusurluluğu etkileyen nedenlerin uygulanması da söz konusu olabilecektir. Örneğin zorunluluk hali, cebir veya tehdit etkisiyle fiilin işlenmesi, geçici nedenler (virüs nedeniyle kusur yeteneğinin etkilenmesi) vd. nedenler söz konusu olabilir. Doktrinde yapay zekanın kusurunun bulunup bulunmadığı da tartışılmakta ve farklı görüşler ileri sürülmektedir154. Bir görüş, ceza hukukunda sorumlu tutulabilmek için failin doğru veya yanlış yapma arasında karar verme yeteneğinin, bir başka ifadeyle failin kanuna aykırı bir suç işlemeden sakınması yeteneğinin bulunması gerektiğini, dolayısıyla da yapay zekanın kusur değerlendirmesinin konusunu oluşturmayacağını kabul etmektedir. Geleneksel kusur öğretisinde irade özgürlüğüne sahip kişilerin kusur yeteneğinin bulunduğunun kabul edildiği, yapay zekanın ise iradesi özgür olmadığından kusur değerlendirmesine konu olamayacakları belirtilmektedir. Kusur, özgür iradeye sahip kişinin kişinin doğruyu seçmeyip yanlışı yerine getirmesi nedeniyle kınanması olarak kabul edildiğinde teknoloji hangi yönde gelişirse gelişsin, “kusurlu” bir robotun kesinlikle düşünülemeyeceği belirtilmektedir155. Yapay zekalı makineler öğrenme ve karar verme yeteneğine sahip olsalar da kendi özgürlüklerinin bilincinde olmalarının, toplumda kendilerinin hak ve yükümlülüklerin taşıyıcısı olarak görmelerinin mümkün olmadığı belirtilmektedir156.Benzer bir görüş, yapay zekanın suç işlediği sırada davranışıyla doğru mu yoksa yanlış mı yaptığını fark edebilmesi halinde ceza hukuku kapsamında incelemeye 153 Gless/Silverman/Weigends, s. 135. Aynı yönde Kangal, s. 81. 154 Beynine çip takılan kişinin kusurluluğu ile ilgili olarak bkz.: Köken, s. 276, 277. 155 Monika Simmler/Nora Markwalder, “Roboter in der Verantwortung? -Zur Neuauflage der Debatte um den funktionalen Schuldbegriff”, ZSTW, 2017, 129(1), s. 28. 156 Gless/Weigend, s. 569-570; Kangal, s. 65. tabi tutulabileceğini, keza hatalı davranışından kaynaklanan sosyal kınamaya ilişkin bir anlayış geliştirmesini sağlayan düşünsel kapasiteye sahip olması gerektiğini ve nesnel tanıma ve bireysel değerlendirmeye rağmen, yapay zekanın yanlış davranış için bir karar vermeyi seçebilmesi gerektiğini ifade etmekte ve şuan teknik bir cihaz muhtemelen bir insanla benzer bir işleme ve duyusal kapasiteye sahip olmadığı için kusurluluğunun bulunmadığını ifade etmektedir157. Başka bir görüş, kusurluluğun, bir normun ihlal edildiğinin farkında olmaktan daha fazlasını gerektirdiğini, daha ziyade, kişinin kendi davranışları üzerinde ahlaki olarak düşünmesi ve “iyi ya da kötü bilgisinin” oluşması gerektiğini kabul etmektedir. Bir yapay zeka sistemi, bir kural ihlalini sadece istenmeyen bir davranış olarak kaydedebilir, ama bunu bir insan gibi ahlaki boyutuyla algılayamaz158. Diğer bir görüş, cezai kusurluluğun ek bir fonksiyonel karaktere sahip olduğunu, kusurluluğun yüklenmesini özgür iradenin kusurlu hareketine ahlaki bir reaksiyon olarak değil, suçlu tarafından ihlal edilen hukuki geçerliliğe toplum güveninin eski hale iadesi olduğunu ifade etmektedir. Buna göre, bir kişiye cezai suçluluğun yüklenmesi, hukuk normunun geçerliliğini şüpheye düşürme kapasitesine sahip bir kişiyi gerektirmektedir. Kendi geçmişinin farkında olmama kapasitesi ve ahlaki referans sistemine uygun bir şekilde geçmişin değerlendirilmesi, kusurluluğun yüklenmesi için küçük bir (sosyal) anlam ifade edebilir. Bir bilince sahip olmayan bir varlık ahlaki konular üzerine bir diyaloğa giremez ve suçlamalara tepki gösteremez. Dolayısıyla da kusuru olamaz159. Aynı şekilde bazı yazarlar da irade özgürlüklerinin bulunmadığını belirtmektedirler. Ancak yapay zekâ geliştikçe kendi programına ve fiziksel yapısına müdahalelerde bulunup, kendi kendini yeniden yaratabileceğini, belki irade özgürlüğünden söz edilebileceğini belirtmektedirler160. Diğer bir görüş, irade özgürlüğünün fiksiyon olarak kabul edilmesinin düşünülebileceğini, şu anda ise durumun böyle görünmediğini, irade özgürlüğü gibi kavramların hukuk uygulamasındaki önemine çok fazla değer verildiğini, oysa ki irade özgürlüğünün tartışıldığı çok az kararın bulunduğunu161, 157 Lohmann, s. 130-131. 158 Dominika Wigger, Automatisiertes Fahren und strafrechtliche Verantwortlichkeit wegen Fahrlässigkeit, Nomos, 2020, s. 144-145. 159 Görüş için bkz.: Gless/Silverman/Weigends, s. 133, 134. 160 Taşdemir/Özbay/Kireçtepe, s. 819, 820. 161 Son yıllarda yapılan nörobilim çalışmalarda, insanın özgür irade sahibi olduğuna dair inancın bir yanılsama olduğuna dair dikkat çekici veriler ortaya konmaktadır. Haynes’e kusur için kusur yeteneğinin bulunması, haksızlık bilincine sahip olunması ve mazeret nedenlerinin bulunmaması gerektiğini, irade özgürlüğünün doğrudan bir öneminin kalmadığını, dolayısıyla yapay zekanın kusurun koşullarını yerine getirdiği takdirde kusurlu davranışından söz edilebileceğini savunmaktadır162. Bu görüş, fiilin hukuki anlam ve sonuçlarını anlayabilmesi vekararverme(hukuka uygun davranabilme yeteneğine sahip olmasına rağmen hukuka aykırı fiili gerçekleştirmeye karar verme) sürecinde ve bunları dikkate alması konusunun hukukçular nezdinde daha çok çözümleme ve somutlaştırma çabalarını şart kıldığını belirtmektedir163. Diğer bir görüş, robotların ceza sorumluluğunu reddetmekle birlikte robotların irade özgürlüğüne sahip olabilecekleri ve bir hareketi icra etmeye yönelik karar verebilecekleri izlenimini er veya geç bize verebileceklerini, insanlar bakımından da dış dünyadan gördüğümüzün gerçekten özgür hareket edip etmedikleri değil, kararlarından edindiğimiz izlenim olduğunu, ancak bu durumun irade özgürlüğünü reddetmemize sebep olmadığını belirtmektedirler. Bu görüşe göre, iyi bir robot tasarımında ona irade özgürlüğü verilebilir ve robotun yürüdüğü, ayakta durduğu koştuğu, uyuduğu ve ayrıca hırsızlık, öldürme gibi ceza hukuku bakımından önemli bir hareketi gerçekleştirdiği söylenebilir164. Bazı yazarlar da kusurun varlığı için özgür iradenin gerektiğini, robotun cezalandırılabilmesi için ceza hukuku anlamında serbest şekilde hareket edebildiğini ve bu hareketi nedeniyle kınanabilir olduğunu kabul etmemizgerektiğini, yani haksızlığı gerçekleştirmeyecek durumdayken haksızlığı gerçekleştirmeyi tercih etmişolması gerektiğini, ister otonom robot söz konusu olsun ister bir insanın yönlendirdiği robot kol veya mekanizma söz konusu olsun bugün için robotların insanların önceden çizdiği sınırlar içinde ve öngörülen şekilde hareket ettiğini, özgür iradelerinin bulunmadığını, dolayısıyla da kusurlarının bulunmadığını belirtmektedirler. Bunula birlikte teknolojiyle ilgili hususlarda kesin öngörülerden kaçınılması kanaatinde olduğunu, belki de topluluk kusurunda olduğu gibi bir gün ürünlerin de göre, kişi karar vermeden daha önce nedensel etki süreci beyinde tamamlanmakta, kişi daha kararının bilincinde değilken her şey beyinde olup bitmekte, daha sonra karar verilmektedir. Dolayısıyla özgür irade bulunmamaktadır: Mehtap Doğan, Özgür İrade, s. 792, 793. 162 Bkz. Hilgendorf, Können Roboter schuldhaft handeln, s. 129 vd; Kangal, s. 67, 68. 163 Hilgendorf, Otomatikleşmiş Sürüş, s. 454. 164 Jan C. Joerden, “Strafrechtliche Perspektiven der Robotik”, Robotik und Gesetzgebung, (Hrsg.: Eric Hilgendorf/Jan-Philipp Günther), Baden-Baden, 2013, s. 203, 204. kusurundan söz etmenin mümkün hale gelebileceğini ifade etmektedirler165. Diğer bir görüş ise, makine etiği ile uğraşan araştırmacıların, ahlaka dayanan karar alıcı sistemlerin robotlarda programlanıp programlanmadığını belirlemeye çalıştıklarını, bu çabaların emekleme aşamasında olduğunu, zira çoğunlukla ahlaki karar almanın biçimlendirilmesinin fazlasıyla karışık göründüğünü, ancak bazı araştırmacıların yapay zekanın bir gün ahlaki muhakeme ile irtibatlandırılma yeteneğini elde edeceğini umduklarını, robotların kesin kararlar vermek için “ehliyet” ve “kusur” sistemi ile programlanabileceğini, eğer ahlaki temellere dayanan kendi kendini belirleme analoğu olarak işlem görebilirse robotlara kusur sorumluluğunun yüklenmesinin mümkün olacağını ifade etmektedirler166. Fonksiyonel kusur teorisini esas alan167bir görüş yapay zekanın da kusurlu hareket edebileceğini kabul etmektedir. Bu görüş, yapay zekalı makinelerin kusurunu cezanın amacıyla uyumlu olduğunda kabul edilebileceğini, bunun ise sadece yapay zekalı makinelere kişi niteliği verildiğinde ve buna eşlik eden yetenekler yüklendiğinde gerçekleşebileceğini, yapay zekalı makinelere olası bir sorumluluk yüklenmesinin cezanın genel önleme amacı kapsamında gerçekleşmesinin mümkün olduğunu savunmaktadır168. Diğer bir görüş, teknolojik tekillik ya da programlamamız makinenin iletişimsel ve ahlaki bir özerkliğineyolaçtığıdurumda, yapay zekanın sorumlu eylemdebulunabileceğini ve iletişimsel cezalandırmayı anlayabileceğini ifade etmektedir. Bu görüş, kusur ve cezai kınanmanın iletişimsel elverişliliğini cezanın koşulları olarak gerekli görmektedir. Bu koşulların yapay zekaya da uygulanması ve kaçınamadığı bir davranıştan dolayı makineyi kınadığımızda makine otonomisinin ihlal edilmiş olacağını belirtmektedir. Suçla ilgili kınamanın boşa gitmemesi için de yapay zekanın hukuku anlaması ve cezanın amacını kavrayabilmesi gerekir169. Diğer bir görüş ise yapay zekaya sahip araçların eşya olarak ele alınmaları gerektiğini, dolayısıyla hareketlerinin norm ihlali olarak değerlendirilemeyeceği ve kusur yargısının anlamsız olduğunu ifade 165 Koray Doğan, Sürücüsüz Araçlar, s. 3237, 3238. 166 Gless/Silverman/Weigends, s. 134, 135. 167 Bu teori kapsamında ileri sürülen görüşler için bkz.: Kangal, s. 73 vd. 168 Bkz. Simmler/Markwalder, s. 45, 46; Kangal, s. 76. 169 Karsten Gaede, Künstliche Intelligenz -Rechte und Strafenfür Roboter?, Nomos, 2019, s. 64. etmektedir170. Bir başka görüş, kendi kendine öğrenen en modern yapay zeka sistemlerinin davranışlarında bile normatif açıdan motive edilemeyeceklerini, bir tartım sonucunda karar vermediklerini, ya üçüncü kişiler tarafından temin edilen veya kendi gözlemlerinden elde ettiği değerlendirmeye dayandığını, öldürme veya yaralama yasağının normatif anlamını anlamadığını, bir sorun çıktığında (ölüm gibi) gelecek için düzeltmemiz gereken bilişsel bir beklentinin söz konusu olduğunu vurgulamakta, dolayısıyla sorumluluğu kabul etmemektedir171.Bir başka görüş ise robota ceza hukuku açısından kusur izafe edilmesinin şimdilik kabul edilemeyeceğini, ancak ileride özgürlük ve aktiviteyi esas almayan tamamen yeni bir kusur kavramının geliştirilmesiyle mümkün olabileceğini belirtmektedirler172. Diğer bir görüş, sınırlı yapay zekalı bir robotun kusur yeteneğinin tam olmadığını, algılama yeteneğinin azalmışolduğunu, buna karşılık, sınırsız bir yapay zekaya sahip olan bir robotun kusur yeteneğinin tam olması gerektiğini ifade etmektedir173. D. Cezanın Amacı Açısından Yapay zekanın ceza sorumluluğu kabul edildiğinde, cezadan beklenen amacın sağlanması, nasıl cezaların uygulanacağı da önemli bir sorun olarak gözükmektedir174. Çünkü bütün kabuller, değerlendirmeler insana göre yapılmıştır. Bazı yazarlar, yapay zekanın amacına ulaşmasını engelleyen bir netice ile karşılaştığında önlemenin gerçekleşeceğini ifade etmektedirler. Doktrinde bazı yazarlar yapay zekanın, cezalandırmanın anlamını kavrama yeteneğine sahip olmadıkları için onlara uygulanacak herhangi bir şey ile kusurları arasında bağlantının bulunmadığını175, klasik cezalarla cezalandırılmaları halinde önlemenin gerçekleştirilemeyeceğini belirtilmektedir176. Yapay zekalar açısından bugün uygulanan tüm cezaların uygun olmadığını belirtmek gerekir. Bir yapay zekaya, insanlarda uygulanan ceza herhangi bir değişiklik yapmaksızın uygulanabildiğinde veya 170 Seher, s. 58, 60. 171 Görüş için bkz. Kangal, s. 79 172 Joerden, s. 205. 173 Köken, s. 277. 174 Bu konuda ayrıntılı bilgi için bkz.: Ziemann, s. 188-190; Seher, s. 58 vd.; Gaede, s. 66 vd. 175 Gless/Silverman/Weigends, s. 136. 176 Kangal, s. 83, 84. insanlara uygulanan cezanın yapay zekanın özelliğine uydurulmak suretiyle verilmesi mümkün olduğunda yapay ceza açısından da bir cezalandırmanın uygulanacağı belirtilmelidir. Örneğin bu nedenle yapay zekaya para cezası uygulanabilecektir. Ancak yapay zekaya sahip varlıkların çoğunun parası, malı veya kendilerine ait bir banka hesabı olmadığı için ancak yapay zekaya sahip bir varlık kendi malına veya parasına sahip olursa, para cezasının uygulanmasının mümkün olacağı da ifade edilmelidir. Yine hapis cezası, yapay zekâlı varlık bakımından yapay zekaya sahip varlığın belirli bir süre kullanılmaması şeklinde uygulanabilecektir177. Yapay zekanın yazılımının imha edilebileceği, silinebileceği, bunun ölüm cezasına eşdeğer olduğu dile getirilmektedir178. Ancak doktrinde insanlara uygulanan cezai yaptırımlar gibi aynı amaçları tamamlayan yapay zekaya karşı yaptırımlar hayal etmenin zor olduğu da belirtilmektedir. Bir robotun fiziksel tahribi veya bozukluğu bedensel ceza ve hatta ölüm cezasına benzemekle birlikte, yaşama isteği (sağlıklı) aşılanmadığı sürece aynı nitelikte değerlendirilmeyeceği ileri sürülmektedir179. Cezanın ertelenmesi, kamu yararına çalıştırmanın da yapay zeka için uygulanabileceği belirtilmektedir180. Yapay zekanın ceza sorumluluğu kabul edildiğinde cezaya özgü yaptırımların uygulanması da söz konusu olabilecektir. Nitekim bazı yazarlar, yapay zekaya kedine özgü, kanunla düzenlenmiş güvenlik tedbirlerinin uygulanmasının söz konusu olabileceğini belirtmektedirler. Örneğin yapay zekanın öğrendiklerinin dijital müsadere yoluyla silinebileceği ifade edilmektedir181. Yapay zeka alanında yaşanan ve ceza hukuku sorumluluğunun kabul edilmesine yol açacak gelişmeler, cezanı belirlenmesi açısından yalnızca fiilin haksızlık içeriğinin göz önüne alınması sonucunu doğurmayacak (TCK m. 61), aynı zamanda yapay zekanın kendisinin de dikkate alınması neticesini ortaya çıkaracaktır. Ceza hukukunda cezanın belirlenmesinde işlenen fiilin haksızlık içeriğini, cezanın bireyselleştirilmesinde ise faili göz önünde tutarken, yapay zekâya ceza belirlerken yapay zekanın da dikkate alınması 177 Hallevy, s. 136, 138, 140; Sinan Altunç, “Robotlar, Yapay Zeka ve Ceza Hukuku”, <https:// <BR> www.academia.edu/37812174/Robotlar_Yapay_Zeka_ve_Ceza_Hukuku>, Erişim Tarihi 22 Temmuz 2023, s. 21. 178 Hallevy, s. 137; Altunç, s. 21. Ayrıca bkz. Taşdemir/Özbay/Kireçtepe, s. 822, 823. 179 Gless/Silverman/Weigends, s. 136. 180 Hallevy, s. 138, 139. 181 Değirmenci, s. 14. gerekecektir. Bir başka ifadeyle yaptırım açısından hem fiil ceza hukuku hem de fail ceza hukuku geçerli olacaktır. SONUÇ Yapay zeka konusunda yaşanan gelişmeler ceza hukukunu zorlu problemlerle karşı karşıya bırakmakta ve bırakacaktır. Çünkü insanların zarar gördüğü veya tehlikeye uğradığı bir durumda sorumluluk noktasında boşluk bırakılması düşünülemez. Sorumluluk kabul edilmediğinde veya sorumluluk verilmediğinde tehlikeli bir gelişime zemin hazırlanacaktır. Şu an için ceza hukukunda yapay zekanın ceza sorumluluğunun kabul edilmesi ve cezalandırılması söz konusu değilse de zaman içinde ceza hukukunda tartıştığımız bazı hususların anlamını yitireceğini, farklı tartışmaların ortaya çıkacağını, kabul edilen kavramlarda değişikliğe gidileceğini, yeni yorumların yapılacağını ve yapay zekanındenetim altına alınması için yollar üretileceğini söylemek gerekir. Hareket kavramı, dolayısıyla da fail kavramı, taksir, kusur, hak sahibi, tüzel kişilerin sorumluluğu, yaptırım konuları, üzerinde tartışılması ve çözümlenmesi gereken konular olarak karşımıza çıkmaktadır. Bugün için yapay zekanın kedisi cezalandırılamamakla beraber yapay zekanın yazılımcısının, üreticisinin ve kullanıcısının ceza sorumluluğuna gidilmesi mümkündür. Ancak yapay zekanın yazılımcısının, üreticisinin ve kullanıcısının ceza hukuku açısından sorumluluklarının belirlenmesi de her zaman kolay olmamaktadır. Ayrıca yapay zekanın kendileri gibi yapay zekalı sistemler tarafından programlandığında ve üretilebildiğinde sorunun daha da büyüyeceğini belirtmek gerekir. KAYNAKÇA Abanoz Öztürk B, “Derin Sahte (Deepfake) Teknoloji Karşısında Türk Ceza Hukuku”, Yapay Zekâ Temellı̇ Teknolojı̇ler ve Ceza Hukuku, Yapay Zekâ Çalışma Grubu, Yıllık Rapor, 2021, <https://www.istanbulbarosu.org.tr/files/komisyonlar/ <BR>yzcg/2021yzcgyillikrapor.pdf>, Erişim Tarihi 31 Temmuz 2023, s. 6481. Akbulut B, Türk Ceza Hukuku, Genel Hükümler, 9. Baskı, Adalet Yayınevi, 2022. Akkurt SS, “Yapay Zekânın Otonom Davranışlarından Kaynaklanan Hukukî Sorumluluk”, Uyuşmazlık Mahkemesi Dergisi, (13), 2019, s. 39-59. Aksoy H, “Yapay Zekalı Varlıklar ve Ceza Hukuku”, International Journal of Economics, Politics, Humanities & Social Sciences, 4(1), 2021, s. 10-27. Alkan SC, “Yapay Zeka ve Doğal Dil İşleme (NLP)”, <https://www. <BR>hukukvebilisimdergisi.com/yapay-zeka-ve-dogal-dil-isleme-nlp/>, <BR>Erişim Tarihi 29.07.2023. Altunç, S, “Robotlar, Yapay Zeka ve Ceza Hukuku”, <https://www.academia. <BR>edu/37812174/Robotlar_Yapay_Zeka_ve_Ceza_Hukuku>, Erişim Tarihi 22 Temmuz 2023, s. 1-22. Arıkan K, “Bilinç ve Bilinçli Olmak Nedir?”, <https://www.kemalarikan.com/ <BR>bilinc-ve-bilincli-olmak nedir.html#:~:text=%C4%B0ngilizcenin%20 <BR>klasik%20s%C3%B6zl%C3%BCklerinden%20olan%20 <BR>Oxford,ger%C3%A7ekle%C5%9Ftirme%20halinin%20kendisine%20 <BR>bilin%C3%A7%20denmektedir>, Erişim Tarihi 23 Temmuz 2023. Bozkurt Yüksel AE, “Avrupa Komisyonu’nun Yapay Zekâ Tüzük Teklifi’ne Genel Bir Bakış”, TAAD, (51), 2022, s. 19-46. Candan, Hatice, “Adım Adım Makine Öğrenmesi Bölüm 4: Denetimli Öğrenme ve Denetimsiz Öğrenme Arasındaki Fark”, <https://medium. <BR>com/machine-learning-t%C3%BCrkiye/ad%C4%B1m-ad%C4%B1m-makine-%C3%B6%C4%9Frenmesi-b%C3%B6l%C3%BCm<BR>4-denetimli-%C3%B6%C4%9Frenme-ve-denetimsiz<BR>%C3%B6%C4%9Frenme-aras%C4%B1ndaki-fark-4aa174983380>, Erişim Tarihi 4 Ağustos 2023. Centel, N/Zafer, H/Çakmut, Ö, Türk Ceza Hukukuna Giriş, 11. Bası, Beta Basım Yayım Dağıtım, 2020. Çetin M S, “Yapay Zekanın Cezai Sorumluluğu”, İstanbul Barosu Dergisi, 95(5), 2021, s. 122-173. Değirmenci O, “Yapay Zekâ ve Ceza Hukuku Sorumluluğu”, <https://www. <BR>academia.edu/42794137/Yapay_Zeka_ve_Ceza_Sorumluluğu>, Erişim Tarihi 25 Temmuz 2023, s. 1-16. Demirbaş T, Ceza Hukuku, Genel Hükümler, 17. Baskı, Seçkin Yayıncılık, 2022. Doğan K, “Sürücüsüz Araçlar, Robotik Cerrahi, Endüstriyel Robotlar ve Cezai sorumluluk”, D.E.Ü. Hukuk Fakültesi Dergisi, Prof. Dr. Durmuş TEZCAN’a Armağan, 21(Özel S.), 2019, s. 3219-3251. Doğan, K, “Tüzel Kişilerin İdari Para Cezası Sorumluluğunda İsnadiyet Sorunu”, D.E.Ü. Hukuk Fakültesi Dergisi, 17(1), 2015, s.1-77. Doğan M, “Yapay Zekâ ve Özgür İrade: Yapay Özgür İradenin İmkânı”, TRT Akademi, 2021, 6(13), s. 788-811. Doğan, M, “Yapay Zeka ve Bilinç”, <https://turkiye.ai/yapay-zeka-ve<BR>bilinc/>, Erişim Tarihi 23 Temmuz 2023. Dursun S, Disiplinler Arası Bir Yaklaşımla Ceza Hukukunda Hareket Kavramı ve Terimi, Seçkin Yayıncılık, 2021. Dursun S, “Türk Ceza Hukuku Reformunun Ekonomi Ceza Hukukuna Etkileri”, <http://www.selmandursun.com/wp-content/uploads/ <BR>sdursun-tch-reformu-ekonomi-ceza.pdf>, Erişim Tarihi 25 Ağustos 2023, s. 2239-2250. Ercan, C, “Robotların Fiillerinden Doğan Hukuki Sorumluluk Sözleşme Dışı Sorumluluk Hallerinde Çözüm Önerileri”, TAAD, (40), 2019, s. 19-51. Erdoğan, G, “Yapay Zekâ ve Hukukuna Genel Bı̇r Bakış”, AD, (66), 2021, s. 117-192. Eroğlu, A, “Henri Bergson’da Bilinç-Sezgi İlişkisi”, SDÜ Fen Edebiyat Fakültesi Sosyal Bilimler Dergisi, (27), 2012, s. 81-102. Frąckiewicz, Marcin, “Yapay Zeka ve Siber Suçları Önleme: Akıllı Sistemler Siber Tehditleri Tespit Etmeye ve Önlemeye Nasıl Yardımcı Oluyor?”, <https://ts2.space/tr/yapay-zeka-ve-siber-suclari-onleme-akilli<BR> sistemler-siber-tehditleri-tespit-etmeye-ve-onlemeye-nasil-yardimci<BR>oluyor/>, Erişim Tarihi 4 Ağustos 2023. Gaede K, Künstliche Intelligenz -Rechte und Strafenfür Roboter?, Nomos, 2019. Gless S, “’Mein Auto fuhr zu schnell, nicht ich!’-StrafrechtlicheVerantwortung für hochautomatisiertes Fahren”, Intelligente Agenten und das Recht, (Hrsg.: Sabine Gless/Kurt Seelmann), Baden-Baden, 2016, s. 225-251. Gless S/Weigend T, “Intelligente Agenten und das Strafrecht”, ZSTW, 2014, 126(3), s. 561-591. Gless S/Silverman E/Weigend T, “Robotlar Zarara Neden Oluyorsa, Kim Sorumlu Tutulabilir? Kendi Kendini Süren Arabalar ve Cezai Sorumluluk”, (Çev.: Serkan Oğuz), Küresel Bakış, (23), 2017, s. 125147. Gropp W, Strafrecht, Allgemeiner Teil, 3. Auflage, Springer, 2005. Güçlütürk O G, Türk Hukukunda Makine Öğrenmesine Dayalı Yapay Zekada Verinin Hukuka Uygun Şekilde Kullanılması, Galatasaray Üniversitesi Sosyal Bilimler Enstitüsü, Doktora Tezi, 2021. Güner U, “Ekonomik Suçlar ve Ekonomi Ceza Hukukuna İlişkin Yasal Düzenlemeler”, D.E.Ü. Hukuk Fakültesi Dergisi, Prof. Dr. Durmuş TEZCAN’a Armağan, 21(Özel S.), 2019, s. 1411-1442. Hallevy G, “Yapay Zekaya Sahı̇p Varlıkların Cezaı̇ Sorumluluğu -Bı̇lı̇m Kurgudan Yasal Toplumsal Denetı̇me”, (Çev.: Müslim FİNCAN), Küresel Bakış, (24), 2018, s. 111-142 vd. Hilgendorf E, “Können Roboter schuldhaft handeln, Zur Übertragbarkeit unseres normativen Grundvokabulars auf Maschinen”, Jenseits von Mensch und Maschine, (Hrsg.: Susanne Beck), Baden-Baden, 2012, s. 119-132. Hilgendorf E, “Otomatikleşmiş Sürüş ve Hukuku-Genel Bir Bakış”, (Çev.: Barış Atladı), Ceza Hukukunda Robot, Yapay Zeka ve Yeni Teknolojiler, Karşılaştırmalı Güncel Ceza Hukuku Serisi 21 (Editör Yener Ünver), 2021, s. 437-455. İnan Orman M, “Avrupa Birliği Hukukunda İdari Para Cezaları”, Kabahatler Hukuku Yazıları-II, 2018, s. 111-144. Joerden J C, “Strafrechtliche Perspektiven der Robotik”, Robotik und Gesetzgebung, (Hrsg.: Eric Hilgendorf/Jan-Philipp Günther), Baden-Baden, 2013, s. 195-209. Kangal Z T, Yapay Zeka ve Ceza Hukuku, On İki Levha Yayınları, 2021. Kandır M O, “Yapay Zekanın Siber Suçlardaki Rolü”, Hukuk ve Bilişim 3. Nesil Hukuk Dergisi, <https://www.hukukvebilisimdergisi.com/yapay<BR>zekanin-siber-suclardaki-rolu/>, Erişim Tarihi 30 Temmuz 2023. Kara Kılıçarslan S, “Yapay Zekanın Hukukı̇ Statüsü ve Hukukı̇ Kı̇şı̇lı̇ğı̇ Üzerı̇ne Tartışmalar”, YBHD, (2), 2019, s. 363-389. Koca M/ Üzülmez İ, Türk Ceza Hukuku Genel Hükümler, 15. Baskı, Seçkin Yayıncılık, 2022. Kökdemir D, “Yapay Zeka Neredeyse Tamam: Peki Yapay Bilinç?, <https:// www.birgun.net/makale/yapay-zeka-neredeyse-tamam-peki-yapaybilinc-449790>, Erişim Tarihi 22 Temmuz 2023. Köken E, “Yapay Zekânın Cezaı̇ Sorumluluğu”, TAAD, (47), 2021, s. 247286. Lohmann A, Strafrecht im Zeitalter von Künstlicher Intelligenz, Robotik und Recht, Nomos 2021. Okuyucu Ergün G, “Machina Sapiens”, AÜHFD, 72(2), 2023, s. 717-758. Özen Y, “Değerler Felsefesi Açısından İrade ve Bileşenleri (Özgür Bir İrademiz Var Mı?)”, <https://dergipark.org.tr/tr/download/article-file/149874#:~:text=Diğer%20bir%20tanımda%20irade%2C%20 <BR>bir,verme%20gücü%2C%20istenç%20olarak%20tanımlanabilir>, Erişim Tarihi 2 Ağustos 2023, s. 1-14. Özgenç İ, Türk Ceza Hukuku, Genel Hükümler, 18. Bası, SeçkinYayıncılık, 2022. Özmen E, “Algı/Algılama”, <https://psikoloji-psikiyatri.com/algi-algilama/>, Erişim Tarihi 23 Temmuz 2023. Öztemel E, “Yapay Zekâ ve İnsanlığın Geleceği”, <https://tuba.gov.tr/files/ <BR>yayinlar/bilim-ve-dusun/TUBA-978-605-2249-48-2_Ch9.pdf>, Erişim Tarihi 05 Ağustos 2023, s. 99-112. Papuççiyan A, “DeepMind’dan yazılımcılar ile rekabet edebilen yapay zeka: AlphaCode AI”, <https://webrazzi.com/2022/02/03/deepmind-dan<BR> yazilimcilar-ile-rekabet-edebilen-yapay-zeka-alphacode-ai/>, Erişim Tarihi 4 Ağustos 2023. Pormetter R, “Fahrlassigkeitsstrafbarkeit im Zeitalter der Robotik”, Strafrecht und Moderne Technologien, Studien zum deutschen und türkischen Strafrecht, Band 5, (Hrsg.: Gunnar Duttge/Yener Ünver), Seçkin Yayıncılık, 2018, s. 105-118. Roxin C/Greco L, Strafrecht, Allgemeiner Teil I, 5. Baskı, C.H. Beck, 2020. Seher G, “Intelligente Agenten als ‘Personen im Strafrecht?” in-Gless, Sabine/Seelmann, Kurt (Hrsg.), Intelligente Agenten und das Recht, Baden-Baden, 2016, s. 45- 60. Simmler M/Markwalder N, “Roboter in der Verantwortung? -Zur Neuauflage der Debatte um den funktionalen Schuldbegriff”, ZSTW, 2017, 129(1), s. 20-47. Şahin A D, “Otonom Araçların Hukuki. Sorumluluğunun Türk ve Alman Hukuku Kapsamında Değerlendirilmesi”, Suç ve Ceza, 4, 2020, s. 9771026. Taşdemir Ö/Özbay Ü V/ Kireçtepe B O, “Robotların Hukuki ve Cezai Sorumluluğu Üzerine Bir Deneme”, AÜHFD, 69(2) 2020, s. 793-833. Üren Ç, “Yapay Zeka İşinizi Ne Zaman Elinizden Alacak: 10 Sektörden Tahminler”, <https://www.indyturk.com/node/646156/bı̇lı̇m/yapayzeka-işinizi-ne-zaman-elinizden-alacak-10-sektörden-tahminler>, Erişim Tarihi 30 Temmuz 2023. Wigger D, Automatisiertes Fahren und strafrechtliche Verantwortlichkeit wegen Fahrlässigkeit, Nomos, 2020. Yapay Zeka ve Veri Bilimi, Hukuk ve Bilişim Pazar Bülteni, <https://www. <BR>linkedin.com/pulse/hukuk-ve-bilişim-pazar-bülteni-sayı-68-hukuk-ve<BR>bilişim-dergisi/> Erişim Tarihi 27 Temmuz 2023. Yazıcı, AN M, Otonom Aracın Sebep Olduğu Zararlardan Üreticinin Kusursuz Sorumluluğu, Adalet Yayınevi, 2023. Ziemann S, “Wesen Wesen, seid’s gewesen? Zur Diskussion über ein Sttrafrecht für Maschinen”, Robotik und Gesetzgebung, (Hrsg.: Eric Hilgendorf/Jan-Philipp Günther), Baden-Baden, 2013, s. 183-194. 